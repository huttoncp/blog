---
title: 'A Scientist''s Guide to R: Step 2.1. Data Transformation - Part 1'
author: 'Craig Hutton'
date: '2019-12-30'
slug: 
categories:
  - R
  - Reproducible Research
  - Data Cleaning and Transformation
tags:
  - R
  - R basics
header:
  image: ''
  caption: ''
  focal_point: ''
output:
  blogdown::html_page:
    number_sections: true
    toc: yes
---


# **TL;DR**

The 4th post in the [Scientist's Guide to R series](https://craig.rbind.io/post/2019-05-17-asgr-basic-workflow/) introduces data transformation techniques useful for wrangling/tidying/cleaning data. Specifically, we will be learning how to use the 6 core functions (and a few others) from the popular [dplyr](https://www.rdocumentation.org/packages/dplyr/versions/0.7.8) package, perform similar operations in base R, and chain operations with the pipe operator (`%>%`) to streamline the process. 

# **Introduction**

The 4th post in the [Scientist's Guide to R series](https://craig.rbind.io/post/2019-05-17-asgr-basic-workflow/) introduces data transformation techniques useful for wrangling/tidying/cleaning data, which often takes as longer than any other step in the data analysis process. Specifically, we will be learning how to use the 6 core functions or "verbs" of the popular [dplyr](https://dplyr.tidyverse.org/) package to:

1. [filter](https://dplyr.tidyverse.org/reference/filter.html) rows using logical tests with values of specified columns.

2. Easily [select](https://dplyr.tidyverse.org/reference/select.html) a subset of columns.

3. Modify columns or add new ones using [mutate](https://dplyr.tidyverse.org/reference/mutate.html).

4. Obtain descriptive summaries of data using [summarise](https://dplyr.tidyverse.org/reference/summarise.html) (or the equivalent summarize()).

5. Assign a grouping structure to a data frame to enable subsequent dplyr package function calls to be executed within groups using [group_by](https://dplyr.tidyverse.org/reference/group_by.html).

6. [arrange](https://dplyr.tidyverse.org/reference/arrange.html) a data frame for improved readability. 

Some additional relevant functions that build on this foundation will also be covered where appropriate (see below).

While other great packages (and other functions in base R) exist to help you manipulate data, using the dplyr package is perhaps the easiest way to learn these essential data processing techniques. However, if you find yourself working with very large datasets (e.g. > 1,000,000 rows) you might want to check out the [data.table](https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html) package, which emphasizes efficiency and performance over readability and ease of use. 

All dplyr functions accept a data frame or tibble as their first argument and return a data frame as their output. This is a key design feature that enables you to apply a series of operations to a data frame in a chain using the pipe operator (`%>%`), as demonstrated in [section 8](https://craig.rbind.io/post/2019-12-30-asgr-2-1-data-transformation-part-1/#chaining-functions-with-the-pipe-operator).

# **filter()**

`filter()` is the one of two core dplyr verbs you can use for subsetting your data. `filter()` lets you extract a subset of rows using [logical operators](https://craig.rbind.io/post/2019-08-06-asgr-2-0-basic-operations-and-data-structures/#logical-operators). 

To filter a data frame, specify the name of the data frame as the 1st argument, then any number of logical tests for values of variables in the data frame that you want to use as filtering criteria.  

```{r, eval = T, cache = TRUE}
library(dplyr) #load the dplyr package with the library function.
#the dplyr package will be used throughout this tutorial so make sure it is
#loaded before trying to run the examples yourself

df <- starwars #assign the star wars data frame (imported when dplyr is loaded) to the label/name "df"

# inspect the structure

glimpse(df)

# use filter to get a subset of all characters from either Tatooine or Naboo

filter(df, 
       homeworld == "Tatooine" | homeworld == "Naboo") #recall that the vertical bar `|` is the logical operator 'or'

# this is read: filter the data frame "df" to extract rows where the value of
# the variable homeworld is equal to "Tatooine" or homeworld is equal to "Naboo"

#in base R, one equivalent option would be:

df[(df$homeworld == "Tatooine" | df$homeworld == "Naboo"), ]

# notice that the $ is not needed to specify which data set the variable
# "homeworld" is in for filter but it is if you are passing a logical vector to
# subset a data frame using `[]` in base R

# this is because R reads (df$homeworld == "Tatooine" | df$homeworld == "Naboo")
# as a logical test and returns a logical vector, which is then used to specify
# which rows to extract (those with values == TRUE) and which to discard (those
# with values == FALSE). This becomes really clear if you just pull out the
# subsetting predicates and print the result

(df$homeworld == "Tatooine" | df$homeworld == "Naboo")

# to get indices instead of logical values, you can wrap the above in which(), e.g.

ind <- which(df$homeworld == "Tatooine" | df$homeworld == "Naboo") #returns the indices where the criteria are TRUE

ind #calling an object itself without applying any functions to it just prints it to the console

#note that you could also pass a vector of integers to subset a df using `[]`
df[ind, ]

#to negate a logical test, you can use `!` which means "not"
# in the context of subsetting, this negates a logical vector 

!(df$homeworld == "Tatooine" | df$homeworld == "Naboo")

#this is why the logical test for not equal to is "!="
identical(!(df$homeworld == "Tatooine"), df$homeworld != "Tatooine") #use identical() or all.equal() to test for equality between entire R objects

# extract rows for characters who are at least 100 cm tall and are from Naboo
filter(df, height >= 100 & homeworld == "Naboo")

# when using filter(), you can substitute a comma for `&` when specifying multiple criteria
identical(filter(df, height >= 100 & homeworld == "Naboo"),
          
          filter(df, height >= 100, homeworld == "Naboo"))

# multiple or (`|`) clauses can instead be specified using the %in% infix operator
option1 <- filter(df, homeworld == "Tatooine" | homeworld == "Naboo" | homeworld == "Alderaan")

option2 <- filter(filter(df, homeworld %in% c("Tatooine", "Naboo", "Alderaan")))

identical(option1, option2)

# since %in% also returns a logical vector, it can also be negated using `!`, 
# although they give different results if the data contain missing values (NA)

a <- !(df$homeworld == "Tatooine" | df$homeworld == "Naboo" | df$homeworld == "Alderaan")

b <- !(df$homeworld %in% c("Tatooine", "Naboo", "Alderaan"))

all.equal(a, b)

b[is.na(a)] #these missing values were converted to TRUE by %in%

# to avoid this and other problems many functions have with processing NA
# values, it is often best to either remove them or impute them, or use the
# na.rm argument for the function

x <- na.omit(df$homeworld)

c <- !(x == "Tatooine" | x == "Naboo" | x == "Alderaan")

# negating a set of `or` clauses for equality is the same as multiple `and`
# clauses for inequality

d <- x != "Tatooine" & x != "Naboo" & x != "Alderaan"

e <- !(x %in% c("Tatooine", "Naboo", "Alderaan"))

all.equal(c, d, e)

# key point: you can use logical comparisons and vectors for subsetting in R

```

# **select()**

`select()` is the other main dplyr verb for used for subsetting. `select()` lets you extract a subset of columns. 

```{r, eval = T, cache = TRUE}
#in base R, you would extract columns using either [, "names"] or [["name]], or $name
df[, "name"] #[] returns another data frame

head(df[["name"]]) #[[]] returns a 1 dimensional vector. head() just shows the 1st 6 values

df[, c("name", "mass", "hair_color")] #[] can accept a vector of names

#df[[c("name", "mass", "hair_color")]] #[[]] can't and returns an error

#or a logical or integer vector the same length as the number of columns

df[, 1:ncol(df) %% 2 == 0] #columns with even indices


df[, 1:5] #1st 5 columns

#dplyr::select() makes extracting multiple columns even easier
select(df, 
       name, mass, hair_color) #note that names don't have to be quoted

select(df, name:hair_color) #and you can get all columns in a range using unquoted names

#select everything other than a specified column using the subtraction operator "-"
select(df, -hair_color, -mass) 

select(df, -c(name:hair_color)) #everything other than a range of named columns

# dplyr also provides a number of "select helper" functions that allow you to
# select variables using string patterns, e.g.

select(df, contains("m")) #all columns with names that contain the letter m

select(df, starts_with("m")) #all columns with names that start with the letter m 

select(df, ends_with("s")) #all columns with names that end with the letter s 

# there is also a select helper called "matches" that enables you to select columns
# with more complex string patterns using regular expressions 

# a detailed introduction to the "matches" select helper, string manipulation,
# and regular expressions will be covered in a later post.

# see the documentation for select_helpers (from the tidyselect package, which
# is loaded with dplyr) for more info
# ?tidyselect::select_helpers

# you can rearrange columns and rename them during the selection process
select(df, 5:last_col(), 1:4) #select columns 5 to the end, then columns 1 to 4 

# to select() a single column and turn it into a vector (instead of leaving it as a data frame),

all.equal(
  pull(select(df, mass), mass), # wrap it in the pull function (also from dplyr)
  df$mass, # or use the $ symbol
  df[["mass"]] # or the equivalent `[[` operator
  )

```

## renaming columns using select() or rename()

Columns can also be renamed when subsetting with the select() function or without subsetting using the rename() function (also in the dplyr package)

```{r, eval = T, cache = TRUE}
#rename and subset using select
select(df, nm = name, hgt = height, byear = birth_year) #select columns and rename them

#to just rename columns without subsetting, use dplyr::rename() instead of select()
rename(df, nm = name, hgt = height, b_year = birth_year) #returns all columns

#to save the updated names just assign the output back to the same data frame object
renamed_df <- rename(df, nm = name, hgt = height, b_year = birth_year) 

#In base R you can just assign names using a string vector. 
#The main disadvantage of this method is that all variable names have to be specified,
#instead of just the ones that you want to change (which is all you need to do with the rename function)
#Unlike select() or rename(), the base R method also requires that names be assigned in the correct order,
#according to the column indices.

df_names <- names(df) #store the original names

names(df) <- c("nm", "hgt", "mass", 
               "hair_color", "skin_color", "eye_color",
               "b_year") #returns a warning and then all non-specified names become NA

names(df) <- df_names #restore the original names from the vector saved above

```


# **mutate()**

`mutate()` lets you modify or create new columns in a data frame. 

```{r, eval = T, cache = TRUE}
#Say for example that you wanted to calculate the BMI of each character in the starwars data frame

df2 <- select(df, name, height, mass) #extract columns of interest

df3 <- mutate(df2,
       height_in_m  = height/100, #convert height from cm to m, store in new column "height_in_m"
       bmi = mass/(height_in_m^2), #add a column called bmi for the calculated body mass index of each character
       bmi = round(bmi, 1)) #round it to one significant digit/decimal place & assign back to the same name
df3
# assigning a modified variable to the same name overwrites/modifies the column

# note in the above mutate statement I created a new variable then used it in the same function call. 
# this is possible because mutate() evaluates items from left to right

# the equivalent operations in base R would typically involve several steps
# requiring separate assignment of intermediate objects

df2$height_in_m <- df2$height/100

df2$bmi <- df2$mass/(df2$height_in_m^2)

df2$bmi <- round(df2$bmi, 1)
  
all.equal(df2, df3)

# As shown above, mutate lets you combine these steps into a single function call and doesn't
# require you to specify the dataframe$ component multiple times, you only have
# to supply the name of the data frame as the 1st argument.

# the transmute function (also in the dplyr package) is an alternative to mutate that
# only retains variables you specify (i.e. it combines select and mutate in a single step)
# You probably won't use it as often as mutate, but it can be helpful occassionally

transmute(df2,
       height_in_m  = height/100, #convert height from cm to m, store in new column "height_in_m"
       bmi = mass/(height_in_m^2), #add a column called bmi for the calculated body mass index of each character
       bmi = round(bmi, 1))


```

## recoding or creating indicator variables using if_else(), case_when(), or recode()

A common use of mutate (or transmute) is to encode a new variable (or overwrite an existing one) based on values of an existing variable in a data frame using the [recode()](https://dplyr.tidyverse.org/reference/recode.html), [if_else()](https://dplyr.tidyverse.org/reference/if_else.html) or [case_when()](https://dplyr.tidyverse.org/reference/case_when.html) functions in the dplyr package.

if_else is a condensed version of a simple if/else statement with only 2 outcomes: one if the condition specified as the 1st argument evaluates to `TRUE` and one if it evaluates to `FALSE` (i.e. no `else if` components). General control flow operations using conditional statments (`if`, `else`, `else if`, etc.) may be covered in a later blog post... For now I recommend [this section of the advanced R book](https://adv-r.hadley.nz/control-flow.html) for those who want to learn more about it before moving on.

```{r, eval = T, cache = TRUE}

# to create an indicator/dummy/2-level variable (e.g. 1/0, T/F) you can use
# if_else() (or ifelse()):

if_else(df$height > 180, #part 1. logical test
        "tall", #part 2. value if TRUE
        "short") #part 1. value if FALSE (should be same classs as the value if TRUE)

# use mutate to add it to an existing data frame

mutate(select(df, name, height), #apply mutate to a subset of the data using a nested select call
       tall_or_short = if_else(height > 180, 
                              "tall", 
                              "short")) 

# to specify more than 2 conditions/outputs you can use case_when():
mutate(select(df, name, height), 
       size_class = case_when(height > 200 ~ "tall", #logical_test ~ value_if_TRUE,
                              height < 200 &  height > 100 ~ "medium", 
                              height < 100 ~ "short")
       ) 


# you can recode a variable using recode():

recoded_using_recode <- mutate(select(df, name, hair_color),
       hair_color = recode(hair_color, #the variable you want to recode
                           "blond" = "BLOND",#old_value = new_value
                           "brown" = "BROWN") #you can recode any number of values this way
       #unspecified values are unaltered
       ) 

recoded_using_recode

# unforunately, unlike other dplyr functions, recode()-ed values are specified as
# "old_value" = "new_value" instead of the more common "new" = "old" scheme used
# by select() and rename()

# an alternative would be to use case_when(), e.g.:

recoded_using_case_when <- mutate(select(df, name, hair_color),
       hair_color = case_when(hair_color == "blond" ~ "BLOND",
                              hair_color == "brown" ~ "BROWN", 
                              TRUE ~ as.character(hair_color)))

identical(recoded_using_recode, recoded_using_case_when) 

# This time we add in the "TRUE ~ as.character(hair_color)" part to signify that
# all other non-NA cases should be the existing value of hair color as a
# character string; otherwise non-matching values are coded as missing values (`NA`)

# note that recode, like most R functions, returns a copy of the data object, 
# that you have to assign to a name if you want to save it in the environment

#of course you can also recode variables in base R using the assingnment operator:

#`<-` (keyboard shortcut = )

df$hair_color[df$hair_color == "blond"] <- "BLOND"
df$hair_color[df$hair_color == "brown"] <- "BROWN"

#but this modifies the data frame in place, which isn't always what you want
#e.g. if you are just experimenting with a coding scheme and then decide you
#want to change it back you'll have to rerun earlier portions of your R script
#to recover the previous version

```


# **summarise()**

`summarise()` makes it easy to turn a data frame into a smaller data frame of summary statistics.

```{r, eval = T, cache = TRUE}

summary1 <- summarise(df, #as for the other dplyr functions, the data source is specified as the 1st argument
                      n = n(), #n() is a special function for use in summarize that returns the number of values
                      mean_height = mean(height, na.rm = TRUE), #summary stat name in the output = function(column) in the input
                      median_mass = median(mass, na.rm = TRUE))

summary1

#summarise() and summarize() do the same thing and just accommodate different user spelling preferences
summary2 <- summarize(df, #as for the other dplyr functions, the data source is specified as the 1st argument
                      n = n(), #n() is a special function for use in summarize that returns the number of values
                      mean_height = mean(height, na.rm = TRUE), #summary stat name in the output = function(column) in the input
                      median_mass = median(mass, na.rm = TRUE))


identical(summary1, summary2)

```

# **group_by()**

`group_by()` adds an explicit grouping structure to a data frame that can subsequently be used by other dplyr functions to perform operations within each level of the grouping variable or level combination of the grouping variables if you specify multiple grouping variables. This is particularly useful in conjunction with either `summarize()` or `mutate()`, enabling you to calculate summary statistics or transform variables separately for each of the groups defined by `group_by()`. 

```{r, eval = T, cache = TRUE}
#structure of the data before grouping
glimpse(df)

grouped_data <- group_by(df, species) #group the data frame "df" by the variable "species"

class(grouped_data) #new additional class = "grouped_df"

glimpse(grouped_data) #note that the structure now has a groups attribute

#next summarise calculates the specified summary statistics within species
summarise(grouped_data,
          n = n(), 
          mean_height = mean(height, na.rm = TRUE), 
          median_mass = median(mass, na.rm = TRUE))


#summarise and summarize do the same thing and just accommodate different user spelling preferences
identical(summary1, summary2)


#to apply mutate() within each level of a grouping variable, simply use mutate
#on a grouped data frame:
mutated_grouped_data <- mutate(grouped_data, 
                               scaled_mass = scale(mass)) #convert raw masses into standardized masses (i.e. z-scores)

select(mutated_grouped_data, name, mass, scaled_mass) #just print the relevant parts

#note that this is done within species, and the results differ from the same
#operation applied to the ungrouped data
identical(
mutated_grouped_data$scaled_mass,
mutate(df, scaled_mass = scale(mass))$scaled_mass,
)

#it is recommended that you ungroup the data after you're finished mutating it
#if you want subsequent operations to be applied to the entire data frame
#instead of within groups
ungrouped_data <- ungroup(mutated_grouped_data)

glimpse(ungrouped_data) #notice that the groups attribute is no longer there

#and grouped_df is no longer one of the data frame's classes
class(ungrouped_data)

```


# chaining functions with the **pipe operator (%>%)**

Thanks to the [magrittr](https://github.com/tidyverse/magrittr) package, you can use the pipe operator, "%>%", which allows you to apply a series of functions to an object using easily readable code without requiring you to save intermediate objects. 
Note that you don't have to load the magrittr package in a separate call to the library() function since the pipe operator is imported from magrittr automatically when you load the dplyr package.

The pipe operator takes the object on the left and passes it to the first argument of the function to the right. Functions in dplyr and other tidyverse packages take data as the 1st argument. Those function which output the same type of object that they accept as inputs (i.e. the data argument) can be chained using the "%>%" quite easily.  
For example,

```{r, eval = T, cache = TRUE}
# %>% lets you turn this nested code (evaluated from the inside out)... 

arrange(summarize(group_by(select(starwars, species, mass), species), 
                  mean_mass = mean(mass, na.rm = T)), desc(mean_mass))

# ...which could also be written more clearly like this:

arrange(#evaluated last
  
  summarize(#evaluated 3rd
    
    group_by(#evaluated 2nd
      
      select(#evaluated 1st
        
        starwars, species, mass), #1. from the starwars data frame, select() the columns species and mass
      
      species), #2. then use group_by() to group the data by species
    
    mean_mass = mean(mass, na.rm = T)),  #3. then use summarize() to calculate the mean() mass for each species
  
  desc(mean_mass)) #4. then arrange() the summary data frame by mean_mass in descending order


# ... into this tidy chain, which reads much more naturally

sorted_mass_by_sw_species_chained <- starwars %>% #take the starwars df  
  
  select(species, mass) %>% #pass it to the 1st agrument of select() (i.e. data), then extract species and mass
  
  group_by(species) %>% #output of select() becomes the input to the 1st argument of group_by(); group it by species
  
  summarise(mean_mass = mean(mass, na.rm = T)) %>% #summarise() the grouped data frame to get the mean mass per group
  
  arrange(desc(mean_mass)) # arrange the grouped summary by the mean mass column in descending order

sorted_mass_by_sw_species_chained

# the order of operations using %>% is so much more obvious and produces code
# that can be read at a glance and doesn't require intermediate objects which
# each occupy memory, e.g.

starwars_sub <- select(starwars, 
                       species, mass) 

grouped_starwars_sub <- group_by(starwars_sub, 
                                 species) 

mass_by_sw_species <- summarise(grouped_starwars_sub, 
                                mean_mass = mean(mass, na.rm = T))

sorted_mass_by_sw_species_unchained <- arrange(mass_by_sw_species, 
                                               desc(mean_mass)) 

# and then have to be deleted afterwards to reclaim the memory 
rm(starwars_sub)
rm(grouped_starwars_sub)
rm(mass_by_sw_species)

identical(sorted_mass_by_sw_species_chained, sorted_mass_by_sw_species_unchained) #the output is the same
  
# note: the keyboard shortcut for %>% is ctrl + shift + M (at least on Windows machines)

```


# navigation

Click [here](https://craig.rbind.io/post/2019-08-06-asgr-2-0-basic-operations-and-data-structures/) to go back to the previous post. A link to the next one (data transformation - part 2 - reshaping data with the tidyr package) will be added as soon as I have time to write it. 

# notes

* To explore dplyr and in more depth checkout [chapter 5 of R for data science](https://r4ds.had.co.nz/transform.html). 

* To learn more about subsetting using base R I highly recommend [chapter 4 of the Advanced R book](https://adv-r.hadley.nz/subsetting.html).

* For more details on other data manipulation techniques in base R checkout the [official R introductory manual](https://cran.r-project.org/doc/manuals/r-release/R-intro.pdf). 

Thank you for visiting my blog. I welcome any suggestions for future posts, comments or other feedback you might have. Feedback from beginners and science students/trainees (or with them in mind) is especially helpful in the interest of making this guide even better for them.
