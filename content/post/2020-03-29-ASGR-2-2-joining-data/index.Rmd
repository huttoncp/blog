---
title: 'A Scientist''s Guide to R: Step 2.2 - Joining Data with dplyr'
author: 'Craig Hutton'
date: '2020-03-29'
slug: 
categories:
  - R
  - Reproducible Research
  - Data Cleaning and Transformation
tags:
  - R
  - R basics
header:
  image: ''
  caption: ''
  focal_point: ''
output:
  blogdown::html_page:
    number_sections: true
    toc: yes
---


# **TL;DR**

Out in the real world you may often find yourself working with data from multiple sources.  It will probably be stored in separate files and you'll need to combine them before you can attempt to answer any of your research questions. This post will show you how you can combine data frames using another set of [dplyr](https://dplyr.tidyverse.org/reference/join.htm) functions called **joins**.


# **Introduction**

The 6th post of the [Scientist's Guide to R series](https://craig.rbind.io/post/2019-05-17-asgr-basic-workflow/) is all about using joins to combine data. While tidy data organized nicely into a single `.csv` or `.xlsx` spreadsheet may be provided to you in courses, in the real world you'll often collect data from multiple sources often only containing one or two similar "key" columns (like subject ID #) and have to combine pieces of them to do anything interesting. This type of data is called **relational data**, since the datasets are *related* through common key column(s). [Relational databases](https://www.ibm.com/cloud/learn/relational-databases) are how most data are stored in modern non-academic organizations.

Fortunately, a package we're already familiar with from a couple of posts ago, [dplyr](https://dplyr.tidyverse.org/), also has a set of functions for combining data with functions called [**"joins"**](https://dplyr.tidyverse.org/reference/join.htm). For this post we will cover the 6 most common joins:

1. `left_join(x, y)` which combines all columns in data frame `x` with those in data frame `y` but only retains rows from `x`.

2. `right_join(x, y)` also keeps all columns but operates in the opposite direction, returning only rows from `y`.  

3. `full_join(x, y)` combines all columns of x with all columns of y and retains all rows from both data frames.

4. `inner_join(x, y)` combines all columns present in either `x` or `y` but only retains rows that are present in both data frames.

5. `semi_join(x, y)` returns the columns from `x` only and *retains* rows of `x` that *are also* present in `y`

6. `anti_join(x, y)` returns the columns from `x` only and *retains* rows of `x` that *are not* present in `y`.

A nice design feature of these functions is that their names and behaviour were [inspired](https://r4ds.had.co.nz/relational-data.html) by analogous functions for joining data in the ubiquitous database management programming language ["Stuctured Query Language" (SQL)](https://en.wikipedia.org/wiki/SQL). Learning dplyr therefore also makes SQL easier to learn in the future, which will be helpful if you ever want to work with data for a [living](https://livebook.manning.com/book/build-your-career-in-data-science/chapter-1/32). 

In case you find yourself working in an environment where only base R is available, we'll also cover how to join data using the base R function [merge()](https://stat.ethz.ch/R-manual/R-devel/library/base/html/merge.html).

Aside from specifying the data frames to be joined, one other thing we need to do is specify the **key column(s)** to be used for aligning the rows prior to joining the data. 

Key columns are specified with the `by` argument, e.g. `inner_join(x, y, by = "subject_id")` adds columns of `y` to `x` for all rows where the values of the "subject_id" column (present in each data frame) match. If the name of the key column differs between the data frames, e.g. "subject_id" in `x` and "subj_id" in `y`, then you have to specify both names using `by = c("subject_id" = "subj_id")` so that the functions know which columns to compare.

A nice feature of the `*_join()` functions is that if you don't specify the `by` argument they will assume that columns with the same names across `x` and `y` are key columns. This is very convenient when the columns with the same names in fact contain the same type of values.


## setup

To demonstrate the use of the join functions, I'll prepare an example of relational data using the [gapminder](https://cran.r-project.org/web/packages/gapminder/gapminder.pdf) dataset for the year 2007 aggregated to the continent level. In this representation of the data, the life expectancy, population, and gdpPercap are stored in separate data frames (called `life_df`, `pop_df`, and `gdp_df` respectively). This sort of arrangement is closer to what you might encouter if the gapminder data were stored in a relational database.

```{r, eval = T, cache = TRUE, message = FALSE}
library(gapminder) #contains the gapminder data

library(dplyr) #functions for manipulating and joining data

life_df <- gapminder %>%
  filter(year >= 1997 & year <= 2007) %>%
  group_by(continent, year) %>% 
  summarise(mean_life_expectancy = mean(lifeExp, na.rm = T)) %>% 
  filter(continent != "Asia") %>% ungroup()

pop_df <- gapminder %>% 
  filter(year >= 1997 & year <= 2007) %>%
  group_by(continent, year) %>% 
  summarise(total_population = sum(pop, na.rm = T)) %>% 
  filter(continent != "Europe") %>%
  ungroup()


gdp_df <- gapminder %>% 
  filter(year == 1997 | year == 2007) %>%
  group_by(continent, year) %>% 
  summarise(total_gdpPercap = sum(gdpPercap, na.rm = T)) %>% 
  ungroup()

```

Recall that we can print a view of the structure of each data frame using the glimpse function from dplyr

```{r, eval = T, cache = TRUE, message = FALSE}
life_df %>% glimpse()

pop_df %>% glimpse()

gdp_df %>% glimpse()

```

or print them to the console using the names

```{r eval=T, message=FALSE, cache=TRUE, paged.print=FALSE}
life_df

pop_df 

gdp_df 

```

From these printouts we can tell that each data frame only has values for some of the continents and/or some of the years that are present in the full gapminder data. I've structured them this way so that it is easier to see how they are joined, as you'll soon find out. 

# **left_join()**

If we wanted to add the population data for each continent that appears in the life expectancy data frame, we could use `left_join()` and the key columns `continent` and `year`.

```{r, eval = T, cache = TRUE, message = FALSE}

#all columns in x will be returned and 
#all columns of y will be returned 
#for rows in the key column that have values in y that match those in x

left_join(x = life_df, 
          y = pop_df, 
          by = c("continent", "year"))

# if the key columns have different names, you can tell the join function which
# columns to use with the equality operator

#1st I'll just rename the continent column for pedagogical purposes
life_df_renamed <- rename(life_df, 
                          cont = continent)

names(life_df_renamed)

left_join(x = life_df_renamed, 
          y = pop_df, 
          #since the continent column is now called "cont" in life_df, 
          #we have to tell left_join which columns to match on.
          #You'll get an error if you try by = c("continent", "year") this time
          by = c("cont" = "continent",
                 "year"))


```

Note that the total_population column from `pop_df` has been joined to `life_df` based on matching values in the key columns that appear in both data frames. Since we used a **left join** and Europe is listed as a continent in `life_df`, the row for it is returned in the joined data frame. However, because there are no population values for Europe in `pop_df`, these rows are filled with `NA`s under the total_population column.   


# **right_join()**

A **right join** is basically the same thing as a left_join but in the other direction, where the 1st data frame (x) is joined to the 2nd one (y), so if we wanted to add life expectancy and GDP per capita data we could either use: 

i) a `right_join()` with `life_df` on the *left* side and `gdp_df` on the *right* side, or 

ii) a `left_join()` with `gdp_df` on the *left* side and `life_df` on the *right* side

... and get the same result with only the columns arranged differently...

```{r, eval = T, cache = TRUE, message = FALSE}
#Also, since the key columns have the same names in each data frame we don't have to specify them
#we can also pipe in the 1st dataframe using the pipe operator (`%>%`)

rj <- life_df %>% right_join(gdp_df) 

rj

lj <- gdp_df %>% left_join(life_df)

identical(rj, lj)

identical(rj, select(lj, 1, 2, 4, 3))

```

This time there are missing values for Asia's mean life expectancy because Asia does not appear in the continent column of life_df (but it does appear in gdp_df), and no rows for the year 2002 because 2002 does not appear in the "year" key column of gdp_df.


# **full_join()**

After aligning rows by matches in the key column(s), a **full join** retains all rows that appear in `x` or `y`

```{r, eval = T, cache = TRUE, message = FALSE}
life_df %>% 
  full_join(gdp_df) %>% 
  arrange(year, continent) #sort by year then by continent

```

The output now includes rows for the year 2002, which were present in `life_df` but not in `gdp_df`. It also includes rows for `Asia`, which are present in `gdp_df` but are missing from `life_df`. As you can see, a full join retains all of the data, filling in missing values where necessary.

Left joins, right joins, and full joins are also collectively referred to as *outer joins* because they retain the observations from at least one of the joined tables. This excellent set of diagrams from [R for Data Science (R4DS)](https://r4ds.had.co.nz/) can help you build an intuitive sense of how these outer joins work:

![source: https://r4ds.had.co.nz/relational-data.html](https://d33wubrfki0l68.cloudfront.net/9c12ca9e12ed26a7c5d2aa08e36d2ac4fb593f1e/79980/diagrams/join-outer.png)


# **inner_join()**

Often you may only want to work with rows which have matching entries in both data sources. Since only some rows are retained, we're no longer dealing with an outer join. In this case you could use `inner_join()`, which returns all rows in both `x` and `y` but only rows with that appear in the key columns of both data frames. 

```{r, eval = T, cache = TRUE, message = FALSE}
life_df %>% 
  inner_join(gdp_df)

```

This time we only get data for 1997 and 2007 even though `life_df` has values for 2002 because `gdp_df` did not contain any data for 2002. We also don't get any data for Asia, which was present in `gdp_df`, because there was no data for Asia in `life_df`.

This diagram from [R4DS](https://r4ds.had.co.nz/) shows you another example of how an inner join works:

![source: https://r4ds.had.co.nz/relational-data.html](https://d33wubrfki0l68.cloudfront.net/3abea0b730526c3f053a3838953c35a0ccbe8980/7f29b/diagrams/join-inner.png)


# **semi_join()**

So far we've been filtering rows based on matches in the key columns but extacting all columns from both data frames. The other two main dplyr join functions are available for situations where you only want to keep the columns of one data frame (`x`). 

`semi_join(x, y)` filters the rows of `x` to retain only those that also appear in `y`

```{r, eval = T, cache = TRUE, message = FALSE}
life_df %>% 
  semi_join(pop_df)
```


This time we only get the columns from life_df and we've dropped rows for Europe because Europe only appears under the continent key column for life_df and not pop_df. 

Here is the [R4DS](https://r4ds.had.co.nz/) semi-join diagram showing that only columns and rows from table 1 are retained as a second example:

![source: https://r4ds.had.co.nz/relational-data.html](https://d33wubrfki0l68.cloudfront.net/028065a7f353a932d70d2dfc82bc5c5966f768ad/85a30/diagrams/join-semi.png)

# **anti_join()**

In contrast to **semi joins**, **anti joins** return the rows `x` that do **not** appear in `y`. 

```{r, eval = T, cache = TRUE, message = FALSE}
life_df %>% 
  anti_join(pop_df)
```

As you can see, anti joins can be very useful if you want to know which rows are excluded due to mismatches in the key columns. Checking for consistencies and inconsistencies between data sources is an important part of the data cleaning process and can often help to uncover data entry or coding errors that should be fixed prior to conducting any analyses.

[R4DS](https://r4ds.had.co.nz/) diagram showing how the anti-join works:

![source: https://r4ds.had.co.nz/relational-data.html](https://d33wubrfki0l68.cloudfront.net/f29a85efd53a079cc84c14ba4ba6894e238c3759/c1408/diagrams/join-anti.png)

# building data frames using **bind_rows()** or **bind_cols()**

If you have two data frames with the same columns, you can combine their rows using `dplyr::bind_rows()` or `rbind()`. `rbind()` is best suited for rowwise combinations of vectors or matrices, while `bind_rows()` is better for combining data frames. In my experience, the most common reason to use either would be to add data for new cases to a data frame, so I will only demonstrate `bind_rows()` here. For example, say we decided to add the gapminder life expectancy data for Asia to life_df:

```{r, eval = T, cache = TRUE, message = FALSE}
#first get the data for asia from the original gapminder dataset
asia_life_exp <- gapminder %>%
  filter(continent == "Asia",
         between(year, 1997, 2007)) %>% #between is a shortcut for (column >= value & column <= value) 
  group_by(continent, year) %>% 
  summarise(mean_life_expectancy = mean(lifeExp, na.rm = T))

#then add it to the top of life_df
bind_rows(asia_life_exp, life_df) 

```


If we instead had two data frames with the same cases/rows but different columns (and no common key columns to enable the use of joins), we could combine them using `dplyr::bind_cols()` or `cbind()`. Again, `bind_cols()` is preferred over `cbind()` for combining data frames by column. However, if you're only adding a few columns, `dplyr::mutate()` or a `"df$newcol <- newcol"` statement per column to add would also work.

For example, if we were provided with each column of the gapminder dataframe as separate vectors (each with values in identical order), without any common key columns among any of the fragments, we could reconstruct the orginal gapminder data frame using `bind_cols()`, e.g.:

```{r, eval = T, cache = TRUE, message = FALSE}

ctry <- gapminder$country

ctin <- gapminder$continent

yr <-  gapminder$year

le <- gapminder$lifeExp

pop <- gapminder$pop

gdp <- gapminder$gdpPercap

bound_gap <- bind_cols("country" = ctry, #add names using "name" = vector syntax
                       "continent" = ctin, 
                       "year" = yr, "lifeExp" = le, 
                       "pop" = pop, 
                       "gdpPercap" = gdp)

identical(gapminder, bound_gap)

#the main difference between cbind() and bind_rows() is that bind_rows returns a
#tibble

```

When considering the use of `rbind()`/`bind_rows()` or `cbind()`/`bind_cols()` **you must keep in mind that because no key columns are checked for matching values you need to be sure that the columns (when binding rows) or rows (when binding columns) are arranged in exactly the same order** for each portion of the dataframe before binding the pieces together. This approach can be very error prone, particularly in cases where data cleaning or analysis is being done collaboratively. 

For this reason **I strongly recommend that you** make use of key columns and **combine data using joins whenever possible**.

## **add_row()**

If you only wanted to add a single row to a data frame, you can use `tibble::add_row()` and (recall that the tibble package is also part of the [tidyverse](https://www.tidyverse.org/)). Let's say (hypothetically of course) we found out that the mean life expectancy for countries in Africa had gone up to 56 for the year 2012. We could add this row as follows:

```{r, eval = T, cache = TRUE, message = FALSE}
updated_life_df <- life_df %>% 
  tibble::add_row(continent = "Africa", year = 2012, mean_life_expectancy = 56) %>%  #specify values to be added using column = value syntax
  arrange(continent, year)

updated_life_df #now the value we added appears in the printout of the data frame
```

# joining 3 or more data frames

Joining 3 or more data frames is also pretty easy using dplyr, just pipe the output of a join into another join. This is incredibly simple if they all have key columns with the same names. For example, if I wanted to combine `life_df`, `pop_df` and `gdp_df` and keep rows present in any of them, all I have to do is:

```{r, eval = T, cache = TRUE, message = FALSE}
combined_data <- life_df %>% 
  full_join(pop_df) %>% #life_df is inserted as the 1st argument i.e. data frame "x" of the full_join
  full_join(gdp_df) #the output of the previous join is passed to the first argument of the second full_join

combined_data #now it's all together, using what could be condensed into a single line of code

# Alternatively, I could use full_join(life_df, pop_df) %>% full_join(gdp_df)

# or full_join(full_join(life_df, pop_df), gdp_df)

```

This is another example of how nested function calls can be easier to read when written in series with the pipe operator (`%>%`), which I covered in more detail [here](https://craig.rbind.io/post/2019-12-30-asgr-2-1-data-transformation-part-1/#chaining-functions-with-the-pipe-operator).

# **merge()**

In the very unlikely event that you find yourself having to combine relational data but are working on a computer that only has base R and no admin priviledges to enable you to install dplyr, have no fear! You can use the `merge()` function from base R to perform **left joins**, **right joins**, **inner joins**, and **full joins**. 

In addition to the `x` and `y` arguments that need to be used to specify the data frames to be joined and the `by` argument that indicates which key columns to use, the type of join is determined via the `all.x` and `all.y` arguments

```{r, eval = T, cache = TRUE, message = FALSE}
# inner join/merge

ij_merge <- merge(life_df, pop_df,
            all.x = F, all.y = F) #the default merge/join is an inner join, in which all.x and all.y are both FALSE

ij_dplyr <- inner_join(life_df, pop_df) %>% 
  as.data.frame() #removes the tibble class which the merge result doesn't have

all.equal(ij_merge, ij_dplyr)

#full join/merge
fj_merge <- merge(life_df, pop_df,
            all.x = T, all.y = T) #set (all.x = T and all.y = T) or (all = T), to perform a full join

fj_dplyr <- full_join(life_df, pop_df) %>% 
  as.data.frame() %>%
  arrange(continent)

all.equal(fj_merge, fj_dplyr)

#for a left join, all.x should be set to TRUE and all.y to FALSE
lj_merge <- merge(life_df, pop_df,
            all.x = T, all.y = F) 

lj_dplyr <- left_join(life_df, pop_df) %>% as.data.frame()

all.equal(lj_merge, lj_dplyr)


#for a right join, all.x should be set to FALSE and all.y to TRUE
rj_merge <- merge(life_df, pop_df,
            all.x = F, all.y = T) 

rj_dplyr <- right_join(life_df, pop_df) %>% as.data.frame()

all.equal(rj_merge, rj_dplyr)



```

Why bother with dplyr joins if `merge()` can do so much? Simply because the dplyr code is easier to read and the dplyr functions are faster. Unfortunately, merge also can't handle semi joins or anti joins, so you'd have to do a bit more work to achieve the same results without dplyr.

If you've followed along, congratulations! You now know how the basics of combining data frames in with dplyr joins and base R. Just practice these operations a few times on your own and joins will seem trivial!

# Navigation

Click [here](https://craig.rbind.io/post/2020-01-25-asgr-2-1-data-transformation-part-2/) to go back to the previous post on reshaping data with tidyr or [here](https://craig.rbind.io/post/2020-06-28-asgr-2-3-string-manipulation/) to go to the next post on string manipulation with stringr.

# Notes

  * You can learn more about joins, working with relational data, and the *set operation functions* in `R` [here](https://r4ds.had.co.nz/relational-data.html).
  
  * You can learn more about `SQL` [here](https://www.w3schools.com/sql/default.asp). 

  * The author of dplyr, [Hadley Wickham](http://hadley.nz/), also wrote the **dbplyr** package, which translates dplyr to SQL for you so you can actually query databases directly using dplyr code or even view the [SQL code translations](https://dbplyr.tidyverse.org/articles/sql-translation.html). You can learn more about dbplyr [here](https://dbplyr.tidyverse.org/). The code translation is really helpful if you're trying to learn SQL. 

Thank you for visiting my blog. I welcome any suggestions for future posts, comments or other feedback you might have. Feedback from beginners and science students/trainees (or with them in mind) is especially helpful in the interest of making this guide even better for them.

This blog is something I do as a volunteer in my free time. If you've found it helpful and want to give back, [coffee donations](https://www.buymeacoffee.com/huttoncp) would be appreciated. 

<script type="text/javascript" src="https://cdnjs.buymeacoffee.com/1.0.0/button.prod.min.js" data-name="bmc-button" data-slug="huttoncp" data-color="#FF5F5F" data-emoji=""  data-font="Cookie" data-text="Buy me a coffee" data-outline-color="#000000" data-font-color="#ffffff" data-coffee-color="#FFDD00" ></script>

