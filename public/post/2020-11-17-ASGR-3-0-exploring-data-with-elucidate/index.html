<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.3.0">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Dr. Craig P. Hutton">

  
  
  
    
  
  <meta name="description" content="1 TL;DR2 Introduction3 Installation &amp; setup4 interrogating data4.1 checking for row copies()4.2 count()-ing unique values4.3 describe()-ing missingness &amp; extreme values5 descriptives5.1 describe() a vector5.2 grouped descriptions5.3 describe_all() columns in a data frame5.4 confidence intervals6 to see, look6.1 Anscombe’s lesson: numeric descriptions can be misleading6.2 plot_*-ting data with elucidate7 interacting with data representations8 fix ’er up9 performance evaluations9.">

  
  <link rel="alternate" hreflang="en-us" href="/post/2020-11-17-asgr-3-0-exploring-data-with-elucidate/">

  


  

  

  

  

  

  

  
  
  
  <meta name="theme-color" content="#2962ff">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.0/css/all.css" integrity="sha384-aOkxzJ5uQz7WBObEZcHvV5JvRW3TUc2rNPA7pe3AwnsUohiw1Vj2Rgx2KSOkF5+h" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    

    

  

  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Montserrat:400,700|Roboto:400,400italic,700|Roboto+Mono">
  

  
  
  
  <link rel="stylesheet" href="/css/academic.min.dd3b7994ab53a1ddaf2421ab58c1587f.css">

  

  
  
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-140167948-1', 'auto');
      ga('set', 'anonymizeIp', true);
      ga('require', 'eventTracker');
      ga('require', 'outboundLinkTracker');
      ga('require', 'urlChangeTracker');
      ga('send', 'pageview');
    </script>
    <script async src="//www.google-analytics.com/analytics.js"></script>
    
    <script async src="https://cdnjs.cloudflare.com/ajax/libs/autotrack/2.4.1/autotrack.js" integrity="sha512-HUmooslVKj4m6OBu0OgzjXXr+QuFYy/k7eLI5jdeEy/F4RSgMn6XRWRGkFi5IFaFgy7uFTkegp3Z0XnJf3Jq+g==" crossorigin="anonymous"></script>
    
  
  

  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="/post/2020-11-17-asgr-3-0-exploring-data-with-elucidate/">

  
  
  
  
    
  
  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="twitter:site" content="@huttoncp">
  <meta property="twitter:creator" content="@huttoncp">
  
  <meta property="og:site_name" content="Craig Hutton, PhD">
  <meta property="og:url" content="/post/2020-11-17-asgr-3-0-exploring-data-with-elucidate/">
  <meta property="og:title" content="A Scientist&#39;s Guide to R: Step 3.0 - exploring data with elucidate | Craig Hutton, PhD">
  <meta property="og:description" content="1 TL;DR2 Introduction3 Installation &amp; setup4 interrogating data4.1 checking for row copies()4.2 count()-ing unique values4.3 describe()-ing missingness &amp; extreme values5 descriptives5.1 describe() a vector5.2 grouped descriptions5.3 describe_all() columns in a data frame5.4 confidence intervals6 to see, look6.1 Anscombe’s lesson: numeric descriptions can be misleading6.2 plot_*-ting data with elucidate7 interacting with data representations8 fix ’er up9 performance evaluations9."><meta property="og:image" content="/post/2020-11-17-asgr-3-0-exploring-data-with-elucidate/featured.png">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2020-11-30T00:00:00&#43;00:00">
  
  <meta property="article:modified_time" content="2020-11-30T00:00:00&#43;00:00">
  

  

<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.0.3/cookieconsent.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.0.3/cookieconsent.min.js"></script>
<script>
  window.addEventListener("load", function(){
    window.cookieconsent.initialise({
      "palette": {
        "popup": {
          "background": "#2962ff",
          "text": "#fff"
        },
        "button": {
          "background": "#fff",
          "text": "#2962ff"
        }
      },
      "theme": "classic",
      "content": {
        "message": "This website uses cookies to ensure you get the best experience on our website.",
        "dismiss": "Got it!",
        "link": "Learn more",
        "href": "/privacy/"
      }
    })});
</script>


  

  <title>A Scientist&#39;s Guide to R: Step 3.0 - exploring data with elucidate | Craig Hutton, PhD</title>

</head>
<body id="top" data-spy="scroll" data-target="#TableOfContents" data-offset="71" >
  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" role="textbox" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="/"><img src="/img/Picture1.png" alt="Craig Hutton, PhD"></a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
        <span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">

      
      
      <ul class="navbar-nav mr-auto">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#skills">
            
            <span>Skills</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#experience">
            
            <span>Experience</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#posts">
            
            <span>Posts</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#publications">
            
            <span>Publications</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#accomplishments">
            
            <span>Awards</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#contact">
            
            <span>Contact</span>
            
          </a>
        </li>

        
        

      
      </ul>
      <ul class="navbar-nav ml-auto">
      

        

        
        <li class="nav-item">
          <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        

        
        <li class="nav-item">
          <a class="nav-link js-dark-toggle" href="#"><i class="fas fa-moon" aria-hidden="true"></i></a>
        </li>
        

      </ul>

    </div>
  </div>
</nav>


<article class="article" itemscope itemtype="http://schema.org/Article">

  













<div class="article-header d-xl-none">
  <div class="featured-image" style="background-image: url('/post/2020-11-17-asgr-3-0-exploring-data-with-elucidate/featured_huca0fead370fcca78acb3fc7b4ff23967_35843_800x0_resize_lanczos_2.png');"></div>
  
</div>


<div class="container-fluid split-header d-none d-xl-block">
  <div class="row">
    <div class="col-6">
      <div class="split-header-content">
        <h1 itemprop="name">A Scientist&#39;s Guide to R: Step 3.0 - exploring data with elucidate</h1>

        

        



<meta content="2020-11-30 00:00:00 &#43;0000 UTC" itemprop="datePublished">
<meta content="2020-11-30 00:00:00 &#43;0000 UTC" itemprop="dateModified">

<div class="article-metadata">

  
  

  
  <span class="article-date">
    
    
      
    
    <time>Nov 30, 2020</time>
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    43 min read
  </span>
  

  
  
  <span class="middot-divider"></span>
  <a href="/post/2020-11-17-asgr-3-0-exploring-data-with-elucidate/#disqus_thread"></a>
  

  
  
  <span class="middot-divider"></span>
  <span class="article-categories">
    <i class="fas fa-folder"></i>
    <a href="/categories/r/">R</a>, <a href="/categories/reproducible-research/">Reproducible Research</a>, <a href="/categories/data-exploration/">data exploration</a>, <a href="/categories/data-interrogation/">data interrogation</a>, <a href="/categories/data-visualisation/">data visualisation</a>, <a href="/categories/descriptive-statistics/">descriptive statistics</a></span>
  

  

</div>


        















        
<div class="share-box" aria-hidden="true">
  <ul class="share">
    <li>
      <a class="twitter"
         href="https://twitter.com/intent/tweet?text=A%20Scientist%27s%20Guide%20to%20R%3a%20Step%203.0%20-%20exploring%20data%20with%20elucidate&amp;url=%2fpost%2f2020-11-17-asgr-3-0-exploring-data-with-elucidate%2f"
         target="_blank" rel="noopener">
        <i class="fab fa-twitter"></i>
      </a>
    </li>
    <li>
      <a class="facebook"
         href="https://www.facebook.com/sharer.php?u=%2fpost%2f2020-11-17-asgr-3-0-exploring-data-with-elucidate%2f"
         target="_blank" rel="noopener">
        <i class="fab fa-facebook-f"></i>
      </a>
    </li>
    <li>
      <a class="linkedin"
         href="https://www.linkedin.com/shareArticle?mini=true&amp;url=%2fpost%2f2020-11-17-asgr-3-0-exploring-data-with-elucidate%2f&amp;title=A%20Scientist%27s%20Guide%20to%20R%3a%20Step%203.0%20-%20exploring%20data%20with%20elucidate"
         target="_blank" rel="noopener">
        <i class="fab fa-linkedin-in"></i>
      </a>
    </li>
    <li>
      <a class="weibo"
         href="http://service.weibo.com/share/share.php?url=%2fpost%2f2020-11-17-asgr-3-0-exploring-data-with-elucidate%2f&amp;title=A%20Scientist%27s%20Guide%20to%20R%3a%20Step%203.0%20-%20exploring%20data%20with%20elucidate"
         target="_blank" rel="noopener">
        <i class="fab fa-weibo"></i>
      </a>
    </li>
    <li>
      <a class="email"
         href="mailto:?subject=A%20Scientist%27s%20Guide%20to%20R%3a%20Step%203.0%20-%20exploring%20data%20with%20elucidate&amp;body=%2fpost%2f2020-11-17-asgr-3-0-exploring-data-with-elucidate%2f">
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  </ul>
</div>


      </div>
    </div>
    <div class="col-6">
      <div class="split-header-image">
        <img src="/post/2020-11-17-asgr-3-0-exploring-data-with-elucidate/featured_huca0fead370fcca78acb3fc7b4ff23967_35843_680x500_fill_q90_lanczos_smart1_2.png" itemprop="image" alt="">
        
      </div>
    </div>
  </div>
</div>

<div class="article-container d-xl-none">
  <h1 itemprop="name">A Scientist&#39;s Guide to R: Step 3.0 - exploring data with elucidate</h1>

  

  



<meta content="2020-11-30 00:00:00 &#43;0000 UTC" itemprop="datePublished">
<meta content="2020-11-30 00:00:00 &#43;0000 UTC" itemprop="dateModified">

<div class="article-metadata">

  
  

  
  <span class="article-date">
    
    
      
    
    <time>Nov 30, 2020</time>
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    43 min read
  </span>
  

  
  
  <span class="middot-divider"></span>
  <a href="/post/2020-11-17-asgr-3-0-exploring-data-with-elucidate/#disqus_thread"></a>
  

  
  
  <span class="middot-divider"></span>
  <span class="article-categories">
    <i class="fas fa-folder"></i>
    <a href="/categories/r/">R</a>, <a href="/categories/reproducible-research/">Reproducible Research</a>, <a href="/categories/data-exploration/">data exploration</a>, <a href="/categories/data-interrogation/">data interrogation</a>, <a href="/categories/data-visualisation/">data visualisation</a>, <a href="/categories/descriptive-statistics/">descriptive statistics</a></span>
  

  
    
<div class="share-box" aria-hidden="true">
  <ul class="share">
    <li>
      <a class="twitter"
         href="https://twitter.com/intent/tweet?text=&amp;url="
         target="_blank" rel="noopener">
        <i class="fab fa-twitter"></i>
      </a>
    </li>
    <li>
      <a class="facebook"
         href="https://www.facebook.com/sharer.php?u="
         target="_blank" rel="noopener">
        <i class="fab fa-facebook-f"></i>
      </a>
    </li>
    <li>
      <a class="linkedin"
         href="https://www.linkedin.com/shareArticle?mini=true&amp;url=&amp;title="
         target="_blank" rel="noopener">
        <i class="fab fa-linkedin-in"></i>
      </a>
    </li>
    <li>
      <a class="weibo"
         href="http://service.weibo.com/share/share.php?url=&amp;title="
         target="_blank" rel="noopener">
        <i class="fab fa-weibo"></i>
      </a>
    </li>
    <li>
      <a class="email"
         href="mailto:?subject=&amp;body=">
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  </ul>
</div>


  

</div>

  














</div>



  <div class="article-container">

    <div class="article-style" itemprop="articleBody">
      

<div id="TOC">
<ul>
<li><a href="#tldr"><span class="toc-section-number">1</span> <strong>TL;DR</strong></a></li>
<li><a href="#introduction"><span class="toc-section-number">2</span> <strong>Introduction</strong></a></li>
<li><a href="#installation-setup"><span class="toc-section-number">3</span> <strong>Installation &amp; setup</strong></a></li>
<li><a href="#interrogating-data"><span class="toc-section-number">4</span> <strong>interrogating data</strong></a><ul>
<li><a href="#checking-for-row-copies"><span class="toc-section-number">4.1</span> checking for row <code>copies()</code></a></li>
<li><a href="#count-ing-unique-values"><span class="toc-section-number">4.2</span> <code>count()</code>-ing unique values</a></li>
<li><a href="#describe-ing-missingness-extreme-values"><span class="toc-section-number">4.3</span> <code>describe()</code>-ing missingness &amp; extreme values</a></li>
</ul></li>
<li><a href="#descriptives"><span class="toc-section-number">5</span> <strong>descriptives</strong></a><ul>
<li><a href="#describe-a-vector"><span class="toc-section-number">5.1</span> describe() a vector</a></li>
<li><a href="#grouped-descriptions"><span class="toc-section-number">5.2</span> grouped descriptions</a></li>
<li><a href="#describe_all-columns-in-a-data-frame"><span class="toc-section-number">5.3</span> <code>describe_all()</code> columns in a data frame</a></li>
<li><a href="#confidence-intervals"><span class="toc-section-number">5.4</span> confidence intervals</a></li>
</ul></li>
<li><a href="#to-see-look"><span class="toc-section-number">6</span> <strong>to see, look</strong></a><ul>
<li><a href="#anscombes-lesson-numeric-descriptions-can-be-misleading"><span class="toc-section-number">6.1</span> Anscombe’s lesson: numeric descriptions can be misleading</a></li>
<li><a href="#plot_-ting-data-with-elucidate"><span class="toc-section-number">6.2</span> <code>plot_*</code>-ting data with elucidate</a></li>
</ul></li>
<li><a href="#interacting-with-data-representations"><span class="toc-section-number">7</span> <strong>interacting with data representations</strong></a></li>
<li><a href="#fix-er-up"><span class="toc-section-number">8</span> <strong>fix ’er up</strong></a></li>
<li><a href="#performance-evaluations"><span class="toc-section-number">9</span> performance evaluations</a><ul>
<li><a href="#copies-vs-janitorget_dupes"><span class="toc-section-number">9.1</span> <code>copies()</code> vs <code>janitor::get_dupes()</code></a></li>
<li><a href="#describe_all-vs.-skimrskim"><span class="toc-section-number">9.2</span> <code>describe_all()</code> vs. <code>skimr::skim()</code></a></li>
</ul></li>
<li><a href="#navigation"><span class="toc-section-number">10</span> Navigation</a></li>
<li><a href="#notes"><span class="toc-section-number">11</span> Notes</a></li>
</ul>
</div>

<div id="tldr" class="section level1">
<h1><span class="header-section-number">1</span> <strong>TL;DR</strong></h1>
<p>This post dives into the <a href="https://github.com/bcgov/elucidate">elucidate</a> package and how it can help you explore data using sets of functions for interrogating, describing, visualizing, interacting with, and correcting data. This is a key stage of any analysis that can help you begin to reveal insights into your research questions and I’ll show you how quick and easy it can be with <code>elucidate</code>.</p>
<p><img src="hex-elucidate%20v4.png" width="300"></p>
</div>
<div id="introduction" class="section level1">
<h1><span class="header-section-number">2</span> <strong>Introduction</strong></h1>
<p>The 10th post of the <a href="https://craig.rbind.io/post/2019-05-17-asgr-basic-workflow/">Scientist’s Guide to R series</a> takes us on a journey of discovery through data exploration. In data science, sometimes you can even learn enough in this stage of an analysis to answer basic research questions and reveal something interesting about your data.</p>
<p>In fact, with the right tools it’s easy enough that you can acquire some basic proficiency just from reading this blog post. In this case, the best tool for exploring data (at least at the time of writing) is a new R package called <a href="https://github.com/bcgov/elucidate">elucidate</a>.</p>
<p><code>elucidate</code> helps you <em>explore</em> data by making it efficient and easy to:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Interrogate</strong> data with the <code>copies()</code> and <code>counts*</code> functions from <code>elucidate</code>, in conjunction with <a href="https://craig.rbind.io/post/2019-08-06-asgr-2-0-basic-operations-and-data-structures/#functions-for-describing-the-structural-information-of-data-objects">glimpse</a> from <a href="https://dplyr.tidyverse.org/">dplyr</a>.</p></li>
<li><p><strong>Describe</strong> data with the <code>describe*</code> set of functions for obtaining summary statistics, bootstrapping confidence intervals, and detecting missing values.</p></li>
<li><p>Quickly <strong>visualise</strong> data with the <code>plot_*</code> set of functions.</p></li>
<li><p><strong>interact</strong> with numeric descriptions and visual representations of data using the <code>static_to_dynamic()</code> function.</p></li>
<li><p>Figure out what some of your plot customization options are <em>faster</em> with helper functions like <code>colour_options()</code>, which generates a PDF or image of the available colour options that come pre-loaded with R.</p></li>
<li><p>Correct some of the common data entry errors, anomaly indicator values, and structural inconsistencies seen in real world data using <code>wash_df()</code> and <code>recode_errors()</code>. Here we blur the lines a bit between transformation and exploratory analysis, because data preparation is usually an iterative process in practice.</p></li>
</ol>
<p><code>elucidate</code> is a package I’ve been thrilled to be developing for the Research Branch of the <a href="https://www2.gov.bc.ca/gov/content/governments/organizational-structure/ministries-organizations/ministries/social-development-poverty-reduction">British Columbia Ministry of Social Development &amp; Poverty Reduction</a> since I started working as a public servant last spring. Although I only spend a fraction of my time on <code>elucidate</code>, I’m incredibly grateful for the BC Gov’s ongoing support of the project so I can continue building it for all of us.</p>
<p>R (or python) programming really is one of those <em>transferable research skills</em><a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> that eventually does pay 💰 if you stick with it… on top of all the time you’ll find yourself saving by <a href="https://automatetheboringstuff.com/">“automating the boring stuff”</a>.</p>
<p>Inspired by tidyverse naming conventions, many <code>elucidate</code> function are organized into sets that begin with a common root (e.g. <code>describe*</code>, <code>plot_*</code>, <code>counts*</code>), since this lets you see them all as suggestions while coding in R studio. By default, you can benefit from these tips after typing the 1st 3 characters of the function or object name. It also facilitates code completion via the <code>tab</code> key (in R studio).</p>
<p>Many <code>elucidate</code> functions also accept a data frame as the 1st argument and to return a data frame (or <code>ggplot</code>) so they are compatible with the pipe operator from the <a href="https://magrittr.tidyverse.org/">magrittr</a> package for easy integration into <a href="https://r4ds.had.co.nz/tidy-data.html">“tidy”</a> data processing pipelines. For convenience, the pipe operator (<code>%&gt;%</code>) is also imported when <code>elucidate</code> is loaded.</p>
<p><strong>Bonus!</strong> I recently saw a great <a href="https://twitter.com/lisalendway/status/1312097209752711169?s=20">twitter thread</a> on how to capture screen recordings and include them in R markdown<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> docs, so I’m going to try to implement them later in this very post.</p>
<p><strong>disclaimer</strong> This post will cover how to use R to get descriptive statistics, such as the sample mean, standard deviation, and skewness for numeric variables. I’m going to assume that you’ve learned what these are and how to calculate them in an undergraduate introductory statistics course. If these terms are unfamiliar to you, I strongly recommend visiting Brown University’s awesome <a href="https://seeing-theory.brown.edu/">Seeing Theory</a> website before proceeding.</p>
</div>
<div id="installation-setup" class="section level1">
<h1><span class="header-section-number">3</span> <strong>Installation &amp; setup</strong></h1>
<p>Because it is still rapidly evolving, <code>elucidate</code> is not on <a href="https://cran.r-project.org/web/packages/">CRAN</a> yet (maybe in 2021 ); so you can’t install it the normal way with <code>install.packages()</code>.</p>
<p>Instead, like the <em>development versions</em> of many other packages, you can get it from <a href="https://github.com/">github</a> with:</p>
<pre class="r"><code>install.packages(&quot;remotes&quot;) #only run this 1st if you haven&#39;t installed remotes before

remotes::install_github(&quot;bcgov/elucidate&quot;) 

#note: if you have trouble installing or updating some of the dependencies when
#installing a package from GitHub, try (re)-installing their CRAN versions 1st
#using install.packages().</code></pre>
<p>Then just load it like any other R package, with the <code>library()</code> function:</p>
<pre class="r"><code>library(tidyverse) #for comparisons &amp; the glimpse function</code></pre>
<pre><code>## -- Attaching packages --------------------------------------- tidyverse 1.3.0 --</code></pre>
<pre><code>## v ggplot2 3.3.2     v purrr   0.3.4
## v tibble  3.0.4     v dplyr   1.0.2
## v tidyr   1.1.2     v stringr 1.4.0
## v readr   1.4.0     v forcats 0.5.0</code></pre>
<pre><code>## Warning: package &#39;tibble&#39; was built under R version 4.0.3</code></pre>
<pre><code>## -- Conflicts ------------------------------------------ tidyverse_conflicts() --
## x dplyr::filter() masks stats::filter()
## x dplyr::lag()    masks stats::lag()</code></pre>
<pre class="r"><code>library(janitor) #for comparisons</code></pre>
<pre><code>## 
## Attaching package: &#39;janitor&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:stats&#39;:
## 
##     chisq.test, fisher.test</code></pre>
<pre class="r"><code>library(bench) #for benchmarking

library(elucidate)</code></pre>
<pre><code>## 
## Attaching package: &#39;elucidate&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:base&#39;:
## 
##     mode</code></pre>
<p>For this post, we’ll use the generated dataset, <code>pdata</code> (short for <em>p</em>ractice <em>data</em>), that is imported with <code>elucidate</code>. As usual, we’ll start by inspecting the structure of it with <code>dplyr::glimpse()</code>.</p>
<pre class="r"><code>glimpse(pdata)</code></pre>
<pre><code>## Rows: 12,000
## Columns: 10
## $ id       &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,...
## $ d        &lt;date&gt; 2008-01-01, 2008-01-01, 2008-01-01, 2008-01-01, 2008-01-0...
## $ g        &lt;fct&gt; e, c, d, c, a, a, d, b, e, c, a, a, a, a, a, b, c, b, a, c...
## $ high_low &lt;chr&gt; &quot;high&quot;, &quot;high&quot;, &quot;low&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;low&quot;, &quot;low...
## $ even     &lt;lgl&gt; FALSE, TRUE, FALSE, TRUE, FALSE, TRUE, FALSE, TRUE, FALSE,...
## $ y1       &lt;dbl&gt; 106.26334, 96.47998, 99.33155, 108.94097, 99.65422, 101.59...
## $ y2       &lt;dbl&gt; 117.92654, 107.16036, 96.16405, 101.78278, 113.36807, 113....
## $ x1       &lt;int&gt; 59, 5, 71, 60, 96, 19, 77, 74, 92, 4, 56, 100, 69, 44, 91,...
## $ x2       &lt;int&gt; 116, 101, 111, 130, 196, 163, 133, 191, 106, 134, 142, 111...
## $ x3       &lt;int&gt; 248, 238, 250, 287, 284, 206, 201, 249, 277, 209, 285, 277...</code></pre>
<p>This tells us that we’ve got 12,000 rows and 10 columns of various classes to work with including an “id” and date (“d”) column that could represent distinct observations.</p>
<p>Instead of 12,000 rows, let’s over-sample it with replacement so that there are 1,000,000 rows to allow performance to be more realistically evaluated later on.</p>
<pre class="r"><code>pdata_resampled &lt;- pdata[sample(1:nrow(pdata), 1e6, replace = TRUE),]

dim(pdata_resampled) </code></pre>
<pre><code>## [1] 1000000      10</code></pre>
</div>
<div id="interrogating-data" class="section level1">
<h1><span class="header-section-number">4</span> <strong>interrogating data</strong></h1>
<p><code>dplyr::glimpse()</code> is a great 1st step in the data interrogation process. After learning about the columns names classes, dimensions, and previewing the first several rows of the data, the next thing I usually check is how many copies I have of each row based on columns like subject ID # and date, where I’m hoping that there are as many copies as I should find (i.e. one row per ID and date combination, representing unique measurements). Usually this means making sure there aren’t any unexpected row duplicates. This can easily be evaluated with <code>elucidate::copies()</code>.</p>
<pre class="r"><code>pdata_resampled %&gt;% 
  copies()</code></pre>
<pre><code>## No column names specified - using all columns.</code></pre>
<pre><code>## # A tibble: 1,000,000 x 12
##       id d          g     high_low even     y1    y2    x1    x2    x3
##    &lt;int&gt; &lt;date&gt;     &lt;fct&gt; &lt;chr&gt;    &lt;lgl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;
##  1   117 2015-01-01 a     low      FALSE  149.  98.7    38   159   231
##  2   835 2018-01-01 b     high     FALSE  184. 104.     22   199   236
##  3   673 2018-01-01 c     high     FALSE  247. 118.     14   106   237
##  4   750 2013-01-01 b     low      TRUE   122.  99.3    80   193   272
##  5   865 2011-01-01 c     low      FALSE  140.  99.9    78   183   228
##  6   502 2017-01-01 b     high     TRUE   189. 109.     29   178   274
##  7   554 2017-01-01 d     high     TRUE   235. 106.     17   112   257
##  8   225 2018-01-01 b     high     FALSE  219. 108.     53   195   244
##  9   846 2010-01-01 c     low      TRUE   121.  99.0    18   125   242
## 10   469 2018-01-01 c     high     FALSE  247. 101.     96   161   236
## # ... with 999,990 more rows, and 2 more variables: copy_number &lt;int&gt;,
## #   n_copies &lt;int&gt;</code></pre>
<div id="checking-for-row-copies" class="section level2">
<h2><span class="header-section-number">4.1</span> checking for row <code>copies()</code></h2>
<p>By default, <code>copies()</code> returns all rows in the original data plus an <strong>“n_copies”</strong> column indicating how many copies there are, based on all original columns. In this case, we’ve resampled the same data quite a lot, so there are multiple copies of all original rows. <code>copies()</code> will also preserve the original ordering of the rows unless you ask it to sort the output by the number of copies<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a>. You do so by setting the <strong>sort_by_copies</strong> argument to <code>TRUE</code>. If you also only want to exclude non-duplicated (i.e. completely unique) rows, you can set the <strong>filter</strong> argument to <strong>“dupes”</strong><a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a>.</p>
<pre class="r"><code>pdata_resampled %&gt;% 
  copies(filter = &quot;dupes&quot;, sort_by_copies = TRUE)</code></pre>
<pre><code>## No column names specified - using all columns.</code></pre>
<pre><code>## Duplicated rows detected! 1000000 of 1000000 rows in the input data have multiple copies.</code></pre>
<pre><code>## # A tibble: 1,000,000 x 11
##       id d          g     high_low even     y1    y2    x1    x2    x3 n_copies
##    &lt;int&gt; &lt;date&gt;     &lt;fct&gt; &lt;chr&gt;    &lt;lgl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;
##  1   627 2019-01-01 c     high     FALSE  261.  107.    65   155   243      125
##  2   627 2019-01-01 c     high     FALSE  261.  107.    65   155   243      125
##  3   627 2019-01-01 c     high     FALSE  261.  107.    65   155   243      125
##  4   627 2019-01-01 c     high     FALSE  261.  107.    65   155   243      125
##  5   627 2019-01-01 c     high     FALSE  261.  107.    65   155   243      125
##  6   627 2019-01-01 c     high     FALSE  261.  107.    65   155   243      125
##  7   627 2019-01-01 c     high     FALSE  261.  107.    65   155   243      125
##  8   627 2019-01-01 c     high     FALSE  261.  107.    65   155   243      125
##  9   627 2019-01-01 c     high     FALSE  261.  107.    65   155   243      125
## 10   627 2019-01-01 c     high     FALSE  261.  107.    65   155   243      125
## # ... with 999,990 more rows</code></pre>
<p>As the message informed you, by default <code>copies()</code> will check for duplicates based on all columns unless you specify columns to condition the search upon. This is done by simply listing the <em>unquoted</em> names of the columns. E.g. to check for copies based on just the “id” and “d” (date) columns. This time we’ll use the original version of <code>pdata</code>, to see if each combination of the id and d columns do in fact represents distinct observations…</p>
<pre class="r"><code>pdata %&gt;% 
  copies(id, d, #only consider these columns when searching for copies
         #only return the rows with at least one duplicate
         filter = &quot;dupes&quot;, 
         #sort the result by the number of copies and then specified
         #conditioning variables (in the same order specified). 
         sort_by_copies = TRUE)</code></pre>
<pre><code>## No duplicates detected.</code></pre>
<pre><code>## # A tibble: 0 x 11
## # ... with 11 variables: id &lt;int&gt;, d &lt;date&gt;, g &lt;fct&gt;, high_low &lt;chr&gt;,
## #   even &lt;lgl&gt;, y1 &lt;dbl&gt;, y2 &lt;dbl&gt;, x1 &lt;int&gt;, x2 &lt;int&gt;, x3 &lt;int&gt;,
## #   n_copies &lt;int&gt;</code></pre>
<pre class="r"><code># note: if you didn&#39;t specify any conditioning variables, sort_by_copies will
# only cause copies() to sort the output by the n_copies column</code></pre>
<p>…and they do 😄.</p>
<p>Since the extra copies in the resampled version of the data are meaningless, if this were a real dataset intended for research purposes we would probably want to get rid of them and just keep the 1st copy of each to end up with a distinct<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a> set of rows. This can also be achieved with <code>copies()</code> by instead setting the <strong>filter</strong> argument to <strong>“first”</strong> (or <strong>“last”</strong> for the last copy). In this situation, we actually recover a data frame that is equivalent to the original version of <code>pdata</code>, as demonstrated using <code>identical()</code> after sorting the columns and re-parsing the column classes.</p>
<pre class="r"><code>pdata_distinct &lt;- pdata_resampled %&gt;% #the resampled 1,000,000 row version
  copies(filter = &quot;first&quot;) %&gt;% #only keep the 1st detected copy of each row
  arrange(id, d, g, high_low, even, y1, y2, x1, x2, x3) %&gt;% 
  wash_df()</code></pre>
<pre><code>## No column names specified - using all columns.</code></pre>
<pre class="r"><code>pdata_sorted &lt;- pdata %&gt;% #original data that has not been resampled
  arrange(id, d, g, high_low, even, y1, y2, x1, x2, x3) %&gt;% 
  wash_df()

pdata_distinct %&gt;% glimpse</code></pre>
<pre><code>## Rows: 12,000
## Columns: 10
## $ id       &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2...
## $ d        &lt;date&gt; 2008-01-01, 2009-01-01, 2010-01-01, 2011-01-01, 2012-01-0...
## $ g        &lt;chr&gt; &quot;e&quot;, &quot;e&quot;, &quot;e&quot;, &quot;e&quot;, &quot;e&quot;, &quot;e&quot;, &quot;e&quot;, &quot;e&quot;, &quot;e&quot;, &quot;e&quot;, &quot;e&quot;, &quot;e&quot;...
## $ high_low &lt;chr&gt; &quot;high&quot;, &quot;low&quot;, &quot;high&quot;, &quot;low&quot;, &quot;low&quot;, &quot;low&quot;, &quot;low&quot;, &quot;low&quot;, ...
## $ even     &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FA...
## $ y1       &lt;dbl&gt; 106.26334, 110.03424, 157.88571, 110.80402, 134.40024, 158...
## $ y2       &lt;dbl&gt; 117.92654, 90.61188, 106.97367, 99.20771, 96.22263, 94.980...
## $ x1       &lt;dbl&gt; 59, 14, 14, 69, 93, 26, 47, 79, 19, 87, 75, 86, 5, 73, 25,...
## $ x2       &lt;dbl&gt; 116, 186, 141, 186, 193, 149, 180, 197, 196, 135, 172, 199...
## $ x3       &lt;dbl&gt; 248, 238, 243, 256, 216, 277, 232, 251, 293, 261, 287, 261...</code></pre>
<pre class="r"><code>identical(pdata_distinct, pdata_sorted)</code></pre>
<pre><code>## [1] TRUE</code></pre>
<p>Here the <code>dplyr::arrange()</code> and <code>elucidate::wash_df()</code> steps only serve to standardize the formatting/order of the data without modifying any of the actual values. There will be more about <code>wash_df()</code> later. Now you also know how to eliminate row duplications and recover data that has been oversampled. When working with real data, this most commonly occurs when a <a href="https://craig.rbind.io/post/2020-03-29-asgr-2-2-joining-data/">join</a> goes awry. In fact, I <strong><em>strongly</em></strong> recommend checking for duplicates and filtering them if appropriate both <strong><em>before and after every join</em></strong>, at least the 1st time you’re combining two datasets. <code>copies()</code> can help you with both tasks.</p>
<p><em>Real world relevance</em> - Not long ago I was examining medical records and expected to see one record per person per visit to a health care provider. I was surprised to learn that in fact the data contained one row per service provided, with multiple rows per visit. Checking for duplicates using <code>copies()</code> revealed this important structural aspect of the data that subsequently determined how I prepared it for analysis.</p>
</div>
<div id="count-ing-unique-values" class="section level2">
<h2><span class="header-section-number">4.2</span> <code>count()</code>-ing unique values</h2>
<p>The <code>counts*</code> set of functions helps you quickly check your data for manual entry errors or weird values by providing counts of unique values, where very rare values, and sometimes very common ones, are where such errors tend to show up.</p>
<p><code>counts()</code> returns the unique values and counts for a vector in the form “value_count”, sorted by decreasing count (or ascending if you prefer).</p>
<pre class="r"><code>counts(pdata_resampled$g)</code></pre>
<pre><code>## [1] &quot;a_216374&quot; &quot;b_205163&quot; &quot;d_197590&quot; &quot;e_196166&quot; &quot;c_184707&quot;</code></pre>
<pre class="r"><code>#use order = &quot;a&quot; or &quot;i&quot; to sort in ascending/increasing order</code></pre>
<p><code>counts_all()</code> gives you a list of unique values and their frequency for all columns in a data frame. To avoid printing too much here, we’ll first subset the data by selecting just a few columns to show you what the output looks like.</p>
<pre class="r"><code>pdata_resampled %&gt;% 
  select(d, high_low, even) %&gt;% 
  counts_all()</code></pre>
<pre><code>## $d
##  [1] &quot;2011-01-01_83757&quot; &quot;2010-01-01_83728&quot; &quot;2015-01-01_83611&quot; &quot;2008-01-01_83540&quot;
##  [5] &quot;2016-01-01_83510&quot; &quot;2019-01-01_83436&quot; &quot;2012-01-01_83430&quot; &quot;2018-01-01_83148&quot;
##  [9] &quot;2017-01-01_83087&quot; &quot;2013-01-01_83066&quot; &quot;2009-01-01_82966&quot; &quot;2014-01-01_82721&quot;
## 
## $high_low
## [1] &quot;high_504185&quot; &quot;low_495815&quot; 
## 
## $even
## [1] &quot;TRUE_500015&quot;  &quot;FALSE_499985&quot;</code></pre>
<p>For convenience,<code>elucidate</code> also provides shortcut functions <code>counts_tb()</code> and <code>counts_tb_all()</code> that give you the top and bottom <strong>“n”</strong> unique values (<strong>“n”</strong> is up to 10 by default) in terms of frequency. Here we’ll just ask for up to the top 5 and bottom 5 values,</p>
<pre class="r"><code>pdata_resampled %&gt;% 
  select(d, high_low, even) %&gt;% 
  counts_tb_all(n = 5)</code></pre>
<pre><code>## $d
##        top_v top_n      bot_v bot_n
## 1 2011-01-01 83757 2014-01-01 82721
## 2 2010-01-01 83728 2009-01-01 82966
## 3 2015-01-01 83611 2013-01-01 83066
## 4 2008-01-01 83540 2017-01-01 83087
## 5 2016-01-01 83510 2018-01-01 83148
## 
## $high_low
##   top_v  top_n bot_v  bot_n
## 1  high 504185   low 495815
## 2   low 495815  high 504185
## 
## $even
##   top_v  top_n bot_v  bot_n
## 1  TRUE 500015 FALSE 499985
## 2 FALSE 499985  TRUE 500015</code></pre>
<p>This time we get a list of tibbles instead of a list of vectors, with the top values (“top_v”) and their counts (“top_n”) as a pair of columns, and the bottom values (“bot_v”) beside their counts (“bot_n”). You may have noticed that in cases where there are fewer than “n” unique values, all of them will be shown under each of the <code>top_*</code> and <code>bot_*</code> columns, albeit in opposite orders. As expected, <code>counts_tb()</code> gives you a single tibble showing the top and bottom counts for a single column.</p>
<p>Using the <code>mark()</code> function from the <code>bench</code> package (i.e. <code>bench::mark()</code>), we can see that these functions run reasonably fast on even 1,000,000 rows of data; under 10 seconds on my laptop (Intel i7-9750H processor <span class="citation">@2.6</span> GHz with 16GB of RAM).</p>
<pre class="r"><code>mark(
  #just wrap the expression you want to evaluate the performance of with the
  #bench::mark() function
  pdata_resampled %&gt;% 
    select(d, high_low, even) %&gt;% 
    counts_tb_all(),
  #specify the number of iterations to use for benchmarking with the iterations
  #argument
  iterations = 10) %&gt;% 
  #subset the output to just get the timing &amp; memory usage info
  select(expression, min, median)</code></pre>
<pre><code>## Warning: Some expressions had a GC in every iteration; so filtering is disabled.</code></pre>
<pre><code>## # A tibble: 1 x 3
##   expression                                                          min median
##   &lt;bch:expr&gt;                                                        &lt;bch&gt; &lt;bch:&gt;
## 1 pdata_resampled %&gt;% select(d, high_low, even) %&gt;% counts_tb_all() 8.38s  8.67s</code></pre>
<p>Now you know how easy it can be to check for data entry errors with the <code>counts*</code> set of elucidate functions.</p>
</div>
<div id="describe-ing-missingness-extreme-values" class="section level2">
<h2><span class="header-section-number">4.3</span> <code>describe()</code>-ing missingness &amp; extreme values</h2>
<p>Checking for other anomalies like extreme values (outliers) and how many missing values there are can be achieved with <code>describe()</code>. To start with, we’ll subset the output to just focus on columns relevant these quality indicators.</p>
<pre class="r"><code>pdata_resampled %&gt;% 
  describe(y1) %&gt;% 
  #desctibe() outputs a tibble, which means we can subsequently manipulate the
  #output with dplyr functions, like select()
  select(cases:p_na, p0:p100) </code></pre>
<pre><code>## # A tibble: 1 x 9
##     cases       n    na  p_na    p0   p25   p50   p75  p100
##     &lt;int&gt;   &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1 1000000 1000000     0     0  69.2  121.  145.  181.  289.</code></pre>
<p>From this subset of the output alone we can tell that there are no missing values for y1, which ranges from a minimum (p0) of 69 to a maximum (p100) of 289.2. If p0 is less than ~1.5 x the interquartile range (p75-p25; IQR) away from p25 (= 25th percentile) or p100 is &gt;1.5*IQR greater than p75 (= 75th percentile), we might be concerned about possible outliers in the data. However, unless the deviation is really obvious, you’re better off just looking at a box plot (basically gets you the same information much faster) using <code>elucidate::plot_box()</code>.</p>
<p>Data entry errors can show up here as extreme deviations, like a maximum value of 2,892 or a minimum value of -500 in this case. You should also check to see if most of the p0-p100 percentiles are very close to the same value, which could indicate the presence of ceiling effects or floor effects in the dependent variable<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a>.</p>
<p>Something else to keep in mind is that some data collection protocols use codes like “9999” (when most true values are &lt; 100) to represent invalid responses (e.g. the patient refused to answer the question) or a specific reason data are missing (e.g. equipment failures). If possible, you should check for those sorts of details in any available protocol douments or other <a href="https://en.wikipedia.org/wiki/Metadata">metadata</a> that exist for the data you’re using.</p>
</div>
</div>
<div id="descriptives" class="section level1">
<h1><span class="header-section-number">5</span> <strong>descriptives</strong></h1>
<div id="describe-a-vector" class="section level2">
<h2><span class="header-section-number">5.1</span> describe() a vector</h2>
<p>To get a descriptive summary of a vector you could use the base R <code>summary()</code> function, which is very fast but yields rather limited information. For numeric vectors, <code>summary()</code> will give you the minimum, mean, median, 25th percentile, 75th percentile, and maximum values. It will also tell you how many <code>NA</code>’s there are, but only if some are detected (and not for non-numeric vectors). Alternatively, we can use <code>describe()</code> to get most (or all) of the summary statistics we may need.</p>
<pre class="r"><code>pdata_resampled$y1 %&gt;% summary()</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   69.22  120.88  144.74  153.63  180.79  289.24</code></pre>
<pre class="r"><code>describe(data = pdata_resampled, 
         #if data is a data frame, then you specify the column to describe using
         #the 2nd argument &quot;y&quot;
         y = y1,
         #you can output the results as a data.table instead of a tibble
         #(default is &quot;tibble&quot;) so all output is printed
         output = &quot;dt&quot;)</code></pre>
<pre><code>##      cases       n na p_na   mean     sd    se     p0     p25     p50     p75
## 1: 1000000 1000000  0    0 153.63 42.671 0.043 69.224 120.878 144.738 180.794
##       p100  skew   kurt
## 1: 289.235 0.741 -0.177</code></pre>
<p>In addition to everything provided by <code>summary()</code>, we also get the standard deviation, standard error of the mean, and clearer information on the shape of the distribution via skewness = “skew” and (excess-)kurtosis = “kurt”, where values of either <code>&gt; 1</code> or <code>&lt; -1</code> indicate <a href="https://brownmath.com/stat/shape.htm">non-trivial deviations from normality</a>. In such cases you might want to use the median (p50) and as a measure of central tendency rather than the mean, and the interquartile range (p75-p25) as a measure of the spread of values instead of the standard deviation or standard error. You may also want to look at the distribution with one of the <code>plot_*</code> functions covered below.</p>
<p>We also get information on the presence of missing values, as highlighted previously.</p>
</div>
<div id="grouped-descriptions" class="section level2">
<h2><span class="header-section-number">5.2</span> grouped descriptions</h2>
<p>Experimental research typically focuses on group comparisons (i.e. experimental vs. control), which was a key consideration in developing <code>elucidate</code>. Where possible, <code>elucidate</code> functions make it easy for you to incorporate grouping variables. For example, you can specify any number of them in the <code>describe*</code> functions as unquoted column names via the special <a href="https://www.r-bloggers.com/2015/02/r-three-dots-ellipsis/"><code>...</code></a> argument. For example, to summarise the “y1” numeric variable in <code>pdata</code> for each level of the factor <code>g</code>, we just use:</p>
<pre class="r"><code>pdata_resampled %&gt;% 
  #1st column name is passed to the y argument to indicate the variable to be
  #described
  describe(y1, 
           #subsequent unquoted column names are interpreted as grouping
           #variables
           g)</code></pre>
<pre><code>## # A tibble: 5 x 15
##   g      cases      n    na  p_na  mean    sd    se    p0   p25   p50   p75
##   &lt;fct&gt;  &lt;int&gt;  &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1 a     216374 216374     0     0  134.  25.8 0.055  75.9  112.  132.  156.
## 2 b     205163 205163     0     0  152.  37.8 0.083  74.4  118.  147.  188.
## 3 c     184707 184707     0     0  177.  56.9 0.132  77.0  127.  164.  232.
## 4 d     197590 197590     0     0  174.  43.8 0.099  69.2  138.  175.  214.
## 5 e     196166 196166     0     0  135.  18.6 0.042  75.1  123.  137.  148.
## # ... with 3 more variables: p100 &lt;dbl&gt;, skew &lt;dbl&gt;, kurt &lt;dbl&gt;</code></pre>
<pre class="r"><code>#or more compactly, describe(pdata, y1, g)</code></pre>
<p>It’s really that easy.</p>
</div>
<div id="describe_all-columns-in-a-data-frame" class="section level2">
<h2><span class="header-section-number">5.3</span> <code>describe_all()</code> columns in a data frame</h2>
<p>What if you want to describe all columns of a data frame? What about such a description for each level of one or more grouping variables? This is what <code>describe_all()</code> does.</p>
<p>To describe a subset of variables instead of all of them, just pass the data through <code>dplyr::select()</code> before piping it to <code>describe_all()</code></p>
<pre class="r"><code>pdata_resampled %&gt;%
  #for the sake of brevity we&#39;ll just pick one of each major class to
  #demonstrate class-specific results that are provided
  select(d, g, high_low, even, y2, x1) %&gt;% 
  describe_all()</code></pre>
<pre><code>## $date
## # A tibble: 1 x 8
##   variable   cases       n    na  p_na n_unique start      end       
##   &lt;chr&gt;      &lt;int&gt;   &lt;int&gt; &lt;int&gt; &lt;dbl&gt;    &lt;int&gt; &lt;date&gt;     &lt;date&gt;    
## 1 d        1000000 1000000     0     0       12 2008-01-01 2019-01-01
## 
## $factor
## # A tibble: 1 x 12
##   variable  cases      n    na  p_na n_unique ordered v1_n  v2_n  v3_n  v4_n 
##   &lt;chr&gt;     &lt;int&gt;  &lt;int&gt; &lt;int&gt; &lt;dbl&gt;    &lt;int&gt; &lt;lgl&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;
## 1 g        1.00e6 1.00e6     0     0        5 FALSE   a_21~ b_20~ d_19~ e_19~
## # ... with 1 more variable: v5_n &lt;chr&gt;
## 
## $character
## # A tibble: 1 x 8
##   variable   cases       n    na  p_na n_unique v1_n        v2_n      
##   &lt;chr&gt;      &lt;int&gt;   &lt;int&gt; &lt;int&gt; &lt;dbl&gt;    &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;     
## 1 high_low 1000000 1000000     0     0        2 high_504185 low_495815
## 
## $logical
## # A tibble: 1 x 9
##   variable   cases       n    na  p_na n_TRUE n_FALSE p_TRUE p_FALSE
##   &lt;chr&gt;      &lt;int&gt;   &lt;int&gt; &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;
## 1 even     1000000 1000000     0     0 500015  499985    0.5     0.5
## 
## $numeric
## # A tibble: 2 x 15
##   variable  cases      n    na  p_na  mean    sd    se    p0   p25   p50   p75
##   &lt;chr&gt;     &lt;int&gt;  &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1 y2       1.00e6 1.00e6     0     0 100.   10.1 0.01   60.0  93.4  100.  107.
## 2 x1       1.00e6 1.00e6     0     0  50.5  28.9 0.029   1    25     50    76 
## # ... with 3 more variables: p100 &lt;dbl&gt;, skew &lt;dbl&gt;, kurt &lt;dbl&gt;</code></pre>
<p>Despite the number of calculations and operations that need to be performed, <code>describe_all()</code> also runs pretty quickly for this amount of data, taking <em>under a second</em> and using less than 1 GB of RAM to describe 6 columns of various classes with 1,000,000 values each. This great performance comes from the wonderful <a href="https://rdatatable.gitlab.io/data.table/">data.table</a> package doing the bulk of the heavy lifting for us under the hood.</p>
<pre class="r"><code>mark(
  
  pdata_resampled %&gt;%
    select(d, g, high_low, even, y2, x1) %&gt;% 
    describe_all(),
  
  iterations = 10
) %&gt;% 
  select(expression, min, median, 
         #bench::mark() also tells us how much memory was used
         mem_alloc)</code></pre>
<pre><code>## Warning: Some expressions had a GC in every iteration; so filtering is disabled.</code></pre>
<pre><code>## # A tibble: 1 x 4
##   expression                                                                 
##   &lt;bch:expr&gt;                                                                 
## 1 pdata_resampled %&gt;% select(d, g, high_low, even, y2, x1) %&gt;% describe_all()
## # ... with 3 more variables: min &lt;bch:tm&gt;, median &lt;bch:tm&gt;, mem_alloc &lt;bch:byt&gt;</code></pre>
<p>Again, you can specify any number of grouping variables as unquoted column names that are present in the input data via the <code>...</code>. You can also selectively describe variables of specific classes using <code>describe_all()</code>’s “class” argument, which accepts a character vector of options:</p>
<ul>
<li><strong>“d”</strong>: dates</li>
<li><strong>“f”</strong>: factors</li>
<li><strong>“c”</strong>: character</li>
<li><strong>“l”</strong>: logical</li>
<li><strong>“n”</strong>: numeric</li>
<li><strong>“all”</strong>: shortcut for all of the above &amp; syntactically equivalent to c(“d”, “f”, “c”, “l”, “n”)</li>
</ul>
<p>This can save you time both by avoiding a <code>dplyr::select(where())</code> layer sometimes and also in terms of execution time (especially on larger datasets), because no unnecessary operations are performed upon columns of non-requested classes.</p>
<pre class="r"><code>pdata_resampled %&gt;%
  select(-id) %&gt;% 
  describe_all(g, d, #group by factor variable &quot;g&quot; and date variable &quot;d&quot;
               class = &quot;n&quot;) #only describe numeric variables other than the id column</code></pre>
<pre><code>## # A tibble: 300 x 17
## # Groups:   d, g [60]
##    variable d          g     cases     n    na  p_na  mean    sd    se    p0
##    &lt;chr&gt;    &lt;date&gt;     &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
##  1 x1       2015-01-01 a     17843 17843     0     0  47.0  28.9 0.216     1
##  2 x1       2018-01-01 b     17019 17019     0     0  51.0  28.7 0.22      1
##  3 x1       2018-01-01 c     15387 15387     0     0  46.7  28.5 0.23      1
##  4 x1       2013-01-01 b     17182 17182     0     0  48.6  28.7 0.219     1
##  5 x1       2011-01-01 c     15548 15548     0     0  49.3  28.1 0.225     1
##  6 x1       2017-01-01 b     17091 17091     0     0  50.8  29.3 0.224     1
##  7 x1       2017-01-01 d     16402 16402     0     0  47.0  29.1 0.227     1
##  8 x1       2010-01-01 c     15399 15399     0     0  49.0  28.7 0.232     2
##  9 x1       2019-01-01 e     16519 16519     0     0  49.6  28.4 0.221     1
## 10 x1       2015-01-01 b     17283 17283     0     0  50.4  28.6 0.218     1
## # ... with 290 more rows, and 6 more variables: p25 &lt;dbl&gt;, p50 &lt;dbl&gt;,
## #   p75 &lt;dbl&gt;, p100 &lt;dbl&gt;, skew &lt;dbl&gt;, kurt &lt;dbl&gt;</code></pre>
<pre class="r"><code>#performance when splitting by 2 variables. 
mark(
pdata_resampled %&gt;% select(-id) %&gt;% 
  describe_all(g, d, class = &quot;n&quot;), 

iterations = 10) %&gt;% 
  select(expression, min, median, mem_alloc)</code></pre>
<pre><code>## Warning: Some expressions had a GC in every iteration; so filtering is disabled.</code></pre>
<pre><code>## # A tibble: 1 x 4
##   expression                                                            min
##   &lt;bch:expr&gt;                                                          &lt;bch&gt;
## 1 pdata_resampled %&gt;% select(-id) %&gt;% describe_all(g, d, class = &quot;n&quot;) 1.95s
## # ... with 2 more variables: median &lt;bch:tm&gt;, mem_alloc &lt;bch:byt&gt;</code></pre>
<p>Note that if only one description variable class is requested, you’ll get a data frame back instead of a list of data frames. Moreover, despite having to repeat all calculations across the 5 non-id numeric columns in the 1,000,000 row version of pdata <em>for each of 5 levels of the g factor</em>, we get all of the results in a mere <em>2 seconds</em> using ~1.3GB of RAM!</p>
</div>
<div id="confidence-intervals" class="section level2">
<h2><span class="header-section-number">5.4</span> confidence intervals</h2>
<p>Confidence intervals are a topic that more students tend to struggle with, so I’ll cover it here in more detail. In <a href="https://seeing-theory.brown.edu/frequentist-inference/index.html">frequentist inference</a>, <a href="https://rpsychologist.com/d3/ci/">confidence intervals (CIs)</a> provide an estimate of the possible values a statistic (AKA “parameter”), such as the mean, could take if it were to be repeatedly calculated based on multiple independent samples from the population. In other words, a 95% CI suggests that we are likely to observe a sample mean within the range specified by the CI 95% of the time we measure it using independent random samples from the same population. It is basically an educated guess about what the population value for the parameter is, based on the observed evidence. More concretely, an observed 95% CI for a sample mean of 1-5 suggests that there is a 95% probability that the true population mean is somewhere between 1 and 5.</p>
<p>We often estimate sampling statistics, such as the mean, under the <em>assumption</em> that the true probabilty distribution of what we are measuring closely approximates a well defined distribution in the <a href="https://en.wikipedia.org/wiki/Exponential_family">exponential family</a>, like the “normal” (AKA “Gaussian”) distribution for continuous variables. In behavioural research, this is often reasonable because most complex, polygenic biological &amp; psychological traits tend to be approximately Gaussian (we call this the normality assumption). This is especially true for large sample sizes, due to the <a href="http://www.biostathandbook.com/normality.html">central limit theorem (CLT)</a>. In fact, the CLT teaches us that a mean estimated from a sufficiently large random sample (the larger the better) of independent and identically distributed variables<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a> will be approximately normally distributed <em>irrespective</em> of the shape of the distribution of values in the population. You can see the CLT in action <a href="https://seeing-theory.brown.edu/probability-distributions/index.html#section3">here</a>, which is the best demonstration of it I’ve seen so far. In general, you can benefit from the CLT if you have a sample size <a href="https://statisticsbyjim.com/basics/central-limit-theorem/">&gt;= 30</a>, which means that you don’t need to worry as much about violations of normality for large samples, as they pertain to the putative validity of tests like the analysis of variance or linear regression modeling (topics of future posts).</p>
<p>Bootstrapping<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a> is a computational procedure to estimate the sampling distribution for the statistic of interest (i.e. a CI) by resampling from the observed data with replacement and calculating the statistic for each resample. This process is repeated many times, and observed probability distribution of (re-)sampled statistics is used to define confidence limits for plausible values of the statistic in the underlying population.</p>
<p><code>elucidate</code> makes it easy for you to get either theory-based CIs for the mean or bootstrapped CIs for other descriptive statistics using the <code>stat_ci()</code>, <code>describe_ci()</code>, and <code>describe_ci_all()</code> functions.</p>
</div>
</div>
<div id="to-see-look" class="section level1">
<h1><span class="header-section-number">6</span> <strong>to see, look</strong></h1>
<div id="anscombes-lesson-numeric-descriptions-can-be-misleading" class="section level2">
<h2><span class="header-section-number">6.1</span> Anscombe’s lesson: numeric descriptions can be misleading</h2>
<p>Anscombe’s <a href="https://en.wikipedia.org/wiki/Anscombe%27s_quartet">famous quartet</a> revealed that we can’t always rely upon a set of summary statistics to learn all of the key features of our data. The quartet is a set of four datasets with nearly identical summary statistic values &amp; linear regression parameters but very different distributions. Since these data come pre-loaded with base R, we can just use them (like mtcars) by calling the name “anscombe”. There are 4 pairs of x and y variables, numbered 1-4, to be examined.</p>
<p>We’ll first examine these data using <code>describe_all()</code>.</p>
<pre class="r"><code>anscombe %&gt;% 
  #recall that glimpse doesn&#39;t modify the data itself, so we can use it in the
  #middle of a pipeline
  glimpse() %&gt;% 
  describe_all()</code></pre>
<pre><code>## Rows: 11
## Columns: 8
## $ x1 &lt;dbl&gt; 10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5
## $ x2 &lt;dbl&gt; 10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5
## $ x3 &lt;dbl&gt; 10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5
## $ x4 &lt;dbl&gt; 8, 8, 8, 8, 8, 8, 8, 19, 8, 8, 8
## $ y1 &lt;dbl&gt; 8.04, 6.95, 7.58, 8.81, 8.33, 9.96, 7.24, 4.26, 10.84, 4.82, 5.68
## $ y2 &lt;dbl&gt; 9.14, 8.14, 8.74, 8.77, 9.26, 8.10, 6.13, 3.10, 9.13, 7.26, 4.74
## $ y3 &lt;dbl&gt; 7.46, 6.77, 12.74, 7.11, 7.81, 8.84, 6.08, 5.39, 8.15, 6.42, 5.73
## $ y4 &lt;dbl&gt; 6.58, 5.76, 7.71, 8.84, 8.47, 7.04, 5.25, 12.50, 5.56, 7.91, 6.89</code></pre>
<pre><code>## # A tibble: 8 x 15
##   variable cases     n    na  p_na  mean    sd    se    p0   p25   p50   p75
##   &lt;chr&gt;    &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1 x1          11    11     0     0  9     3.32 1      4     6.5   9    11.5 
## 2 x2          11    11     0     0  9     3.32 1      4     6.5   9    11.5 
## 3 x3          11    11     0     0  9     3.32 1      4     6.5   9    11.5 
## 4 x4          11    11     0     0  9     3.32 1      8     8     8     8   
## 5 y1          11    11     0     0  7.50  2.03 0.613  4.26  6.32  7.58  8.57
## 6 y2          11    11     0     0  7.50  2.03 0.613  3.1   6.70  8.14  8.95
## 7 y3          11    11     0     0  7.5   2.03 0.612  5.39  6.25  7.11  7.98
## 8 y4          11    11     0     0  7.50  2.03 0.612  5.25  6.17  7.04  8.19
## # ... with 3 more variables: p100 &lt;dbl&gt;, skew &lt;dbl&gt;, kurt &lt;dbl&gt;</code></pre>
<p>The means, standard deviations, and standard errors we get suggest that all of the x variables and y variables are quite similar to one another, although the percentiles and skew/kurtosis columns hint that perhaps this isn’t quite true.</p>
</div>
<div id="plot_-ting-data-with-elucidate" class="section level2">
<h2><span class="header-section-number">6.2</span> <code>plot_*</code>-ting data with elucidate</h2>
<p>The best way to know for sure is to look at the data, where we would want to use scatter plots (for combinations of continous variables). R allows you do plot data in a variety of ways, but for now we’ll focus on the <code>elucidate::plot_*</code> function set. <code>plot_scatter()</code> gives us scatter plots. Required arguments are:</p>
<ol style="list-style-type: decimal">
<li>data = data frame containing the x and y variables</li>
<li>y = variable to plot on the y-axis</li>
<li>x = variable to plot on the x-axis</li>
</ol>
<p>We can also opt to add regression lines using the <strong>“regression_line”</strong> argument, and to get a <em>linear</em> regression line, we’ll also set the <strong>“regression_method”</strong> argument to <strong>“lm”</strong> for <strong>l</strong>inear <strong>m</strong>odel. There is also an option to specify the regression formula (more on this in a later post), but if you don’t use it the function will conveniently<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a> tell you which formula is being used by default.</p>
<p><em>N.B.</em> There are quite a few other arguments available to customize scatter plots with <code>plot_scatter()</code>, which I encourage you to check out in the documentation via <code>?plot_scatter()</code>.</p>
<p>The <a href="https://cran.r-project.org/web/packages/gridExtra/vignettes/arrangeGrob.html">gridExtra</a> package provides a helpful function called <code>grid.arrange()</code> that we can use to combine plots into one graphics window/printout as panels.</p>
<pre class="r"><code>p1 &lt;- anscombe %&gt;% 
  plot_scatter(y = y1, x = x1,
               regression_line = TRUE, regression_method = &quot;lm&quot;)

p2 &lt;- anscombe %&gt;% 
  plot_scatter(y = y2, x = x2,
               regression_line = TRUE, regression_method = &quot;lm&quot;)

p3 &lt;- anscombe %&gt;% 
  plot_scatter(y = y3, x = x3,
               regression_line = TRUE, regression_method = &quot;lm&quot;)

p4 &lt;- anscombe %&gt;% 
  plot_scatter(y = y4, x = x4, 
               regression_line = TRUE, regression_method = &quot;lm&quot;)

#since I&#39;m only planning to use grid.arrange() once, I&#39;ll just call it via the
#pacakge::function() syntax, which lets you access any object (yes, R functions
#are objects) from any package that you have installed without loading the rest
#of the package,
gridExtra::grid.arrange(p1, p2, 
                        p3, p4, 
                        #provide unquoted plot object names to be included
                        ncol = 2) #specify ncol or nrow</code></pre>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;
## `geom_smooth()` using formula &#39;y ~ x&#39;
## `geom_smooth()` using formula &#39;y ~ x&#39;
## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="/post/2020-11-17-ASGR-3-0-exploring-data-with-elucidate/index_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>
<p>I think you’ll agree that these variable combinations are quite a bit different than we might have expected based solely on the descriptive stats! Also, basic linear regression only seems like an appropriate choice for the top left plot comparing y1 to x1. I hope you now have a better appreciation of the value of plotting data as well as the utility of metrics like skewness and kurtosis.</p>
<p>Other obviously named <code>plot_*</code> (think “plot_geometry”) convenience functions currently provided by <code>elucidate</code> include:</p>
<ul>
<li><p><code>plot_histogram()</code> = histogram of the binned counts of a continuous variable on the x axis (y is not supplied for this one).</p></li>
<li><p><code>plot_density()</code> = basically a smoothed version of the histogram that shows a kernel density estimate of the probability density function for a continuous variable. I tend to prefer this over the histogram because it is easier to overlay a normal distribution over it (both are on the same “probability density” scale).</p></li>
<li><p><code>plot_box()</code> = “box-and-whiskers” plot of a continuous variable on the y axis by one or more groups (a nominal variable) on the x axis. As you are hopefully aready aware, this shows you the 25th, 50th (i.e. the median), and 75th percentiles for the y-variable plus whiskers extending above the 75th percentile to the maximum value (or 1.5 x the IQR) and below the 25th percentile to the</p></li>
<li><p><code>plot_violin()</code> = violin plot of a continuous variable on the y axis by one or more groups (a nominal variable) on the x axis. Violin plots can reveal the presence of a bimodal distribution (multiple density peaks), which isn’t captured in a box plot.</p></li>
<li><p><code>plot_stat_error()</code> = plot a summary statistic (via the <strong>“stat”</strong> argument), and error bars (via the <strong>“error”</strong> argument) representing a measure of uncertainty in it. You can use this to quickly plot the mean +/- standard error or a confidence interval. The other statistic option</p></li>
</ul>
<p>The 4 plot types I tend to use most often in my research are the density plot, box-and-whiskers plot, scatter plot (as above), and statistic +/- error bars plot, so for this post I will focus on examples for the remaining 3 we haven’t covered so far.</p>
<pre class="r"><code>plot_density()

plot_violin()

plot_box()

plot_scatter()

plot_stat_error()</code></pre>
</div>
</div>
<div id="interacting-with-data-representations" class="section level1">
<h1><span class="header-section-number">7</span> <strong>interacting with data representations</strong></h1>
<p><code>elucidate::static_to_dynamic()</code> is a convenience wrapper for functions in the <a href="https://rstudio.github.io/DT/">DT</a>, <a href="https://glin.github.io/reactable/">reactable</a> and <a href="https://plotly.com/r/">plotly</a> packages that allow you to convert <em>static</em> data frames and ggplot2 graphs into <em>dynamic</em> javascript-based <code>DataTables/reactables</code> and <code>plotly</code> graphs you can interact with. Output from <code>static_to_dynamic()</code> is displayed in the “Viewer” tab of R studio, rather than the console or “Plots” tab.</p>
<p>By default, <code>static_to_dynamic()</code> will convert a data frame into a JavaScript “DataTable” via the <code>DT::DT()</code> function if there are &lt;= 10,000 rows, and a “reactable” via the <code>reactable::reactable()</code> function if there are more than 10,000 rows. This is because (in my experience) the current local-processing implementation of <code>DT()</code> function tends to run slowly (if at all) for data sets that are larger than this threshold, whereas the reactable alternative still works reasonably well with larger data sets (at least 100,000 rows). There is a server-side processing option available for use with the <code>DT()</code> function specifically designed to use with bigger data, but sending your data to be processed on a server isn’t a usually a viable option when you’re working with sensitive or proprietary information (unless you have a private server of course), so it has not been implemented in <code>static_to_dynamic()</code>.</p>
<ul>
<li><p>Either option can be used for data frames with less than 10,000 rows via a <code>reactable</code> argument (<code>TRUE</code> = “reactable”/<code>FALSE</code> = “DT”, default = <code>FALSE</code>). Both options offer search-based filtering for the entire table or for specific columns, (multi-)column sorting capabilities, and a paged viewing format.</p></li>
<li><p><code>DT()</code> provides more functionality overall than <code>reactable()</code>, including Excel-like cell-editing/filling, easier filtering of rows, the ability to rearrange columns by clicking and dragging them, show or hide columns selectively, and options for downloading/copying/printing data. I tend to prefer the <code>DT()</code> version for these features when I’m interacting with smaller tables, like the outputs of the <code>elucidate::describe*</code> functions, but if you find that it is loading too slowly on your machine, try the “reactable” = <code>TRUE</code> argument option instead (which will still be much nicer than the base R <code>View()</code> display).</p></li>
</ul>
<p><!-- ![](static_to_dynamic_DT_demo.gif) --></p>
<ul>
<li><code>reactable()</code> is faster and more efficient than (locally-processed) <code>DT</code>’s, so it still works reasonably well for larger datasets. <code>reactable()</code>, but not <code>DT()</code> also allows you to group the table by one or more columns so that you can collapse/expand certain groups of interest with a simple click of the mouse. The row stripes and highlighting are more clearly visible in the <code>reactable()</code> version as well, and you can also select multiple rows with check boxes to highlight them which can make visually comparing rows of interest a bit easier.</li>
</ul>
<!-- ![](static_to_dynamic_reactable_demo.gif) -->
<ul>
<li><code>ggplot2</code> graphs (i.e. the outputs of the <code>plot_*</code> functions) are converted to interactive <code>plotly</code> graphs via <code>plotly::ggplotly()</code>, which lets you pan around the plot, zoom in to different areas of it, highlight a subset of data points, and more.</li>
</ul>
<!-- ![](static_to_dynamic_ggplotly_demo.gif) -->
</div>
<div id="fix-er-up" class="section level1">
<h1><span class="header-section-number">8</span> <strong>fix ’er up</strong></h1>
<p><code>recode_errors()</code></p>
<p><code>wash_df()</code></p>
</div>
<div id="performance-evaluations" class="section level1">
<h1><span class="header-section-number">9</span> performance evaluations</h1>
<div id="copies-vs-janitorget_dupes" class="section level2">
<h2><span class="header-section-number">9.1</span> <code>copies()</code> vs <code>janitor::get_dupes()</code></h2>
<p>First, I’ll apply each function and standardize the output, then test equivalence of the <strong>“dupes”</strong> <code>filter</code> option to <code>janitor::get_dupes()</code> when several search/grouping columns are specified.</p>
<pre class="r"><code>a &lt;- copies(pdata_resampled, d, high_low, g, x1, filter = &quot;dupes&quot;) %&gt;%
  #remainder of chain/pipeline just serves to standardize the output format
  select(d, high_low, g, x1, g, dupe_count = n_copies, everything()) %&gt;%
  arrange(d, high_low, g, x1, g) %&gt;%
  #this next step is just a shortcut to re-parse the column classes using readr::parse_guess()
  elucidate::wash_df(clean_names = F, remove_empty = F) </code></pre>
<pre><code>## Duplicated rows detected! 1000000 of 1000000 rows in the input data have multiple copies.</code></pre>
<pre class="r"><code>glimpse(a)</code></pre>
<pre><code>## Rows: 1,000,000
## Columns: 11
## $ d          &lt;date&gt; 2008-01-01, 2008-01-01, 2008-01-01, 2008-01-01, 2008-01...
## $ high_low   &lt;chr&gt; &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, ...
## $ g          &lt;chr&gt; &quot;a&quot;, &quot;a&quot;, &quot;a&quot;, &quot;a&quot;, &quot;a&quot;, &quot;a&quot;, &quot;a&quot;, &quot;a&quot;, &quot;a&quot;, &quot;a&quot;, &quot;a&quot;, &quot;...
## $ x1         &lt;dbl&gt; 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,...
## $ dupe_count &lt;dbl&gt; 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, ...
## $ id         &lt;dbl&gt; 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, ...
## $ even       &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, ...
## $ y1         &lt;dbl&gt; 99.62743, 99.62743, 99.62743, 99.62743, 99.62743, 99.627...
## $ y2         &lt;dbl&gt; 107.5344, 107.5344, 107.5344, 107.5344, 107.5344, 107.53...
## $ x2         &lt;dbl&gt; 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 139, 1...
## $ x3         &lt;dbl&gt; 275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 275, 2...</code></pre>
<pre class="r"><code>b &lt;- get_dupes(pdata_resampled, d, high_low, g, x1, g) %&gt;%
  wash_df(clean_names = F, remove_empty = F)

all.equal(a, b)</code></pre>
<pre><code>## [1] TRUE</code></pre>
<p>Good, now we can use the <a href="https://github.com/r-lib/bench">bench::mark()</a> again to compare the performance of <code>copies()</code> to
<code>janitor::get_dupes()</code> when checking for duplicates based on a single variable (column “d” in this case).
As <a href="https://rdatatable.gitlab.io/data.table/articles/datatable-benchmarking.html#avoid-microbenchmark-times-100-">suggested</a>
by the authors of <code>data.table</code>, 10 iterations should be more than sufficient given how much data we’re using for the test.</p>
<pre class="r"><code>bm &lt;- bench::mark(
  copies(pdata_resampled, d, filter = &quot;dupes&quot;),
  get_dupes(pdata_resampled, d), 
  iterations = 10,
  check = FALSE 
    #we won&#39;t check for equal output structures here so the other formatting
    #steps from before don&#39;t need to be included in the timing
)

bm[, c(&quot;expression&quot;, &quot;min&quot;, &quot;median&quot;, &quot;mem_alloc&quot;)] </code></pre>
<pre><code>## # A tibble: 2 x 4
##   expression                                        min   median mem_alloc
##   &lt;bch:expr&gt;                                   &lt;bch:tm&gt; &lt;bch:tm&gt; &lt;bch:byt&gt;
## 1 copies(pdata_resampled, d, filter = &quot;dupes&quot;)   53.5ms   54.2ms     130MB
## 2 get_dupes(pdata_resampled, d)                  97.6ms   98.2ms     184MB</code></pre>
<pre class="r"><code>plot(bm)</code></pre>
<p><img src="/post/2020-11-17-ASGR-3-0-exploring-data-with-elucidate/index_files/figure-html/unnamed-chunk-25-1.png" width="672" /></p>
<p><code>copies()</code> is almost twice as fast when only checking 1 column. It also uses less memory.</p>
<p>What happens when we try to search for duplicates using more than one column?</p>
<pre class="r"><code>bm2 &lt;- bench::mark(
  copies(pdata_resampled, high_low, g, filter = &quot;dupes&quot;),
  get_dupes(pdata_resampled, high_low, g), 
  iterations = 10, 
  check = FALSE
)

bm2[, c(&quot;expression&quot;, &quot;min&quot;, &quot;median&quot;, &quot;mem_alloc&quot;)]</code></pre>
<pre><code>## # A tibble: 2 x 4
##   expression                                                min  median
##   &lt;bch:expr&gt;                                             &lt;bch:&gt; &lt;bch:t&gt;
## 1 copies(pdata_resampled, high_low, g, filter = &quot;dupes&quot;) 36.9ms 37.86ms
## 2 get_dupes(pdata_resampled, high_low, g)                    1s   1.02s
## # ... with 1 more variable: mem_alloc &lt;bch:byt&gt;</code></pre>
<pre class="r"><code>plot(bm2)</code></pre>
<p><img src="/post/2020-11-17-ASGR-3-0-exploring-data-with-elucidate/index_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>
<p>Now the difference is much more noticeable (~35.4 milliseconds vs. ~1.16 seconds; a <em>32-fold</em> speedup in favour of <code>copies()</code>!) and still uses less memory.</p>
<p>What if we condition the search upon all 10 columns (the default behaviour for each function if no variables are specified to base the search on using the <code>...</code> argument)?</p>
<pre class="r"><code>bm3 &lt;- bench::mark(
  copies(pdata_resampled, filter = &quot;dupes&quot;),
  get_dupes(pdata_resampled), 
  iterations = 10,
  check = FALSE
)</code></pre>
<pre><code>## Warning: Some expressions had a GC in every iteration; so filtering is disabled.</code></pre>
<pre class="r"><code>bm3 %&gt;% select(expression, min, median, mem_alloc) </code></pre>
<pre><code>## # A tibble: 2 x 4
##   expression                                     min   median mem_alloc
##   &lt;bch:expr&gt;                                &lt;bch:tm&gt; &lt;bch:tm&gt; &lt;bch:byt&gt;
## 1 copies(pdata_resampled, filter = &quot;dupes&quot;) 136.58ms  152.9ms     130MB
## 2 get_dupes(pdata_resampled)                   1.78s    1.85s     237MB</code></pre>
<pre class="r"><code>plot(bm3)</code></pre>
<p><img src="/post/2020-11-17-ASGR-3-0-exploring-data-with-elucidate/index_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
<p>Here the speed difference is ~14 fold. <code>get_dupes()</code> also uses more memory but, surprisingly, <code>copies()</code> doesn’t at all (thanks to the underlying <code>data.table</code> code).</p>
</div>
<div id="describe_all-vs.-skimrskim" class="section level2">
<h2><span class="header-section-number">9.2</span> <code>describe_all()</code> vs. <code>skimr::skim()</code></h2>
<p>The only other R function that I’m aware of which is comparable to <code>describe_all(data)</code> is <code>skimr::skim()</code>. To describe multiple columns of a data frame within each level of a grouping variable with <code>skimr::skim()</code>, we would also need to pass it through a <code>dplyr::group_by()</code> layer first. To simplify the output a bit we’ll just start with “g” as a grouping variable.</p>
<p>We’ll evaluate performance using the factor “g” as a grouping variable and requesting descriptions of the other 9 columns in <code>pdata_resampled</code>.</p>
<pre class="r"><code>pdata_resampled %&gt;% 
  group_by(g) %&gt;% 
  skimr::skim()</code></pre>
<table>
<caption><span id="tab:unnamed-chunk-28">Table 9.1: </span>Data summary</caption>
<tbody>
<tr class="odd">
<td align="left">Name</td>
<td align="left">Piped data</td>
</tr>
<tr class="even">
<td align="left">Number of rows</td>
<td align="left">1000000</td>
</tr>
<tr class="odd">
<td align="left">Number of columns</td>
<td align="left">10</td>
</tr>
<tr class="even">
<td align="left">_______________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Column type frequency:</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">character</td>
<td align="left">1</td>
</tr>
<tr class="odd">
<td align="left">Date</td>
<td align="left">1</td>
</tr>
<tr class="even">
<td align="left">logical</td>
<td align="left">1</td>
</tr>
<tr class="odd">
<td align="left">numeric</td>
<td align="left">6</td>
</tr>
<tr class="even">
<td align="left">________________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Group variables</td>
<td align="left">g</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: character</strong></p>
<table>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="left">g</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">min</th>
<th align="right">max</th>
<th align="right">empty</th>
<th align="right">n_unique</th>
<th align="right">whitespace</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">high_low</td>
<td align="left">a</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">3</td>
<td align="right">4</td>
<td align="right">0</td>
<td align="right">2</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">high_low</td>
<td align="left">b</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">3</td>
<td align="right">4</td>
<td align="right">0</td>
<td align="right">2</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">high_low</td>
<td align="left">c</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">3</td>
<td align="right">4</td>
<td align="right">0</td>
<td align="right">2</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">high_low</td>
<td align="left">d</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">3</td>
<td align="right">4</td>
<td align="right">0</td>
<td align="right">2</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">high_low</td>
<td align="left">e</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">3</td>
<td align="right">4</td>
<td align="right">0</td>
<td align="right">2</td>
<td align="right">0</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: Date</strong></p>
<table>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="left">g</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="left">min</th>
<th align="left">max</th>
<th align="left">median</th>
<th align="right">n_unique</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">d</td>
<td align="left">a</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">2008-01-01</td>
<td align="left">2019-01-01</td>
<td align="left">2013-01-01</td>
<td align="right">12</td>
</tr>
<tr class="even">
<td align="left">d</td>
<td align="left">b</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">2008-01-01</td>
<td align="left">2019-01-01</td>
<td align="left">2013-01-01</td>
<td align="right">12</td>
</tr>
<tr class="odd">
<td align="left">d</td>
<td align="left">c</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">2008-01-01</td>
<td align="left">2019-01-01</td>
<td align="left">2013-01-01</td>
<td align="right">12</td>
</tr>
<tr class="even">
<td align="left">d</td>
<td align="left">d</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">2008-01-01</td>
<td align="left">2019-01-01</td>
<td align="left">2014-01-01</td>
<td align="right">12</td>
</tr>
<tr class="odd">
<td align="left">d</td>
<td align="left">e</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">2008-01-01</td>
<td align="left">2019-01-01</td>
<td align="left">2013-01-01</td>
<td align="right">12</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: logical</strong></p>
<table>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="left">g</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">mean</th>
<th align="left">count</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">even</td>
<td align="left">a</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.50</td>
<td align="left">FAL: 109137, TRU: 107237</td>
</tr>
<tr class="even">
<td align="left">even</td>
<td align="left">b</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.56</td>
<td align="left">TRU: 115317, FAL: 89846</td>
</tr>
<tr class="odd">
<td align="left">even</td>
<td align="left">c</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.42</td>
<td align="left">FAL: 106826, TRU: 77881</td>
</tr>
<tr class="even">
<td align="left">even</td>
<td align="left">d</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.55</td>
<td align="left">TRU: 108695, FAL: 88895</td>
</tr>
<tr class="odd">
<td align="left">even</td>
<td align="left">e</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.46</td>
<td align="left">FAL: 105281, TRU: 90885</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="left">g</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">mean</th>
<th align="right">sd</th>
<th align="right">p0</th>
<th align="right">p25</th>
<th align="right">p50</th>
<th align="right">p75</th>
<th align="right">p100</th>
<th align="left">hist</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">id</td>
<td align="left">a</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">491.29</td>
<td align="right">299.85</td>
<td align="right">5.00</td>
<td align="right">226.00</td>
<td align="right">483.00</td>
<td align="right">738.00</td>
<td align="right">997.00</td>
<td align="left">▇▇▆▇▇</td>
</tr>
<tr class="even">
<td align="left">id</td>
<td align="left">b</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">488.82</td>
<td align="right">289.16</td>
<td align="right">8.00</td>
<td align="right">229.00</td>
<td align="right">486.00</td>
<td align="right">746.00</td>
<td align="right">993.00</td>
<td align="left">▇▇▆▆▇</td>
</tr>
<tr class="odd">
<td align="left">id</td>
<td align="left">c</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">494.89</td>
<td align="right">265.82</td>
<td align="right">2.00</td>
<td align="right">286.00</td>
<td align="right">484.00</td>
<td align="right">706.00</td>
<td align="right">1000.00</td>
<td align="left">▅▇▇▆▅</td>
</tr>
<tr class="even">
<td align="left">id</td>
<td align="left">d</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">504.08</td>
<td align="right">293.50</td>
<td align="right">3.00</td>
<td align="right">242.00</td>
<td align="right">524.00</td>
<td align="right">747.00</td>
<td align="right">992.00</td>
<td align="left">▇▇▆▇▇</td>
</tr>
<tr class="odd">
<td align="left">id</td>
<td align="left">e</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">526.21</td>
<td align="right">289.73</td>
<td align="right">1.00</td>
<td align="right">267.00</td>
<td align="right">537.00</td>
<td align="right">794.00</td>
<td align="right">998.00</td>
<td align="left">▆▆▆▆▇</td>
</tr>
<tr class="even">
<td align="left">y1</td>
<td align="left">a</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">133.98</td>
<td align="right">25.80</td>
<td align="right">75.86</td>
<td align="right">112.21</td>
<td align="right">132.46</td>
<td align="right">156.26</td>
<td align="right">202.22</td>
<td align="left">▂▇▆▆▁</td>
</tr>
<tr class="odd">
<td align="left">y1</td>
<td align="left">b</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">151.60</td>
<td align="right">37.81</td>
<td align="right">74.35</td>
<td align="right">117.78</td>
<td align="right">146.71</td>
<td align="right">187.89</td>
<td align="right">247.29</td>
<td align="left">▃▇▃▇▁</td>
</tr>
<tr class="even">
<td align="left">y1</td>
<td align="left">c</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">177.06</td>
<td align="right">56.92</td>
<td align="right">77.02</td>
<td align="right">126.62</td>
<td align="right">164.46</td>
<td align="right">232.10</td>
<td align="right">289.24</td>
<td align="left">▅▇▃▆▅</td>
</tr>
<tr class="odd">
<td align="left">y1</td>
<td align="left">d</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">174.01</td>
<td align="right">43.85</td>
<td align="right">69.22</td>
<td align="right">137.63</td>
<td align="right">175.22</td>
<td align="right">213.90</td>
<td align="right">268.21</td>
<td align="left">▂▆▆▇▂</td>
</tr>
<tr class="even">
<td align="left">y1</td>
<td align="left">e</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">134.84</td>
<td align="right">18.63</td>
<td align="right">75.10</td>
<td align="right">122.66</td>
<td align="right">136.65</td>
<td align="right">148.37</td>
<td align="right">186.97</td>
<td align="left">▁▃▇▇▁</td>
</tr>
<tr class="odd">
<td align="left">y2</td>
<td align="left">a</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">100.04</td>
<td align="right">10.00</td>
<td align="right">64.61</td>
<td align="right">93.68</td>
<td align="right">100.09</td>
<td align="right">106.57</td>
<td align="right">135.99</td>
<td align="left">▁▃▇▃▁</td>
</tr>
<tr class="even">
<td align="left">y2</td>
<td align="left">b</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">100.24</td>
<td align="right">10.17</td>
<td align="right">60.72</td>
<td align="right">93.22</td>
<td align="right">100.37</td>
<td align="right">107.13</td>
<td align="right">142.18</td>
<td align="left">▁▃▇▂▁</td>
</tr>
<tr class="odd">
<td align="left">y2</td>
<td align="left">c</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">99.95</td>
<td align="right">10.11</td>
<td align="right">59.96</td>
<td align="right">93.41</td>
<td align="right">100.06</td>
<td align="right">106.74</td>
<td align="right">130.18</td>
<td align="left">▁▂▇▆▁</td>
</tr>
<tr class="even">
<td align="left">y2</td>
<td align="left">d</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">100.09</td>
<td align="right">10.04</td>
<td align="right">66.76</td>
<td align="right">93.28</td>
<td align="right">99.97</td>
<td align="right">107.03</td>
<td align="right">133.43</td>
<td align="left">▁▃▇▃▁</td>
</tr>
<tr class="odd">
<td align="left">y2</td>
<td align="left">e</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">100.16</td>
<td align="right">10.27</td>
<td align="right">62.30</td>
<td align="right">93.06</td>
<td align="right">100.16</td>
<td align="right">107.16</td>
<td align="right">135.75</td>
<td align="left">▁▃▇▅▁</td>
</tr>
<tr class="even">
<td align="left">x1</td>
<td align="left">a</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">51.31</td>
<td align="right">29.03</td>
<td align="right">1.00</td>
<td align="right">26.00</td>
<td align="right">51.00</td>
<td align="right">76.00</td>
<td align="right">100.00</td>
<td align="left">▇▇▇▇▇</td>
</tr>
<tr class="odd">
<td align="left">x1</td>
<td align="left">b</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">49.94</td>
<td align="right">28.89</td>
<td align="right">1.00</td>
<td align="right">25.00</td>
<td align="right">50.00</td>
<td align="right">74.00</td>
<td align="right">100.00</td>
<td align="left">▇▇▇▇▇</td>
</tr>
<tr class="even">
<td align="left">x1</td>
<td align="left">c</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">50.01</td>
<td align="right">28.98</td>
<td align="right">1.00</td>
<td align="right">24.00</td>
<td align="right">49.00</td>
<td align="right">75.00</td>
<td align="right">100.00</td>
<td align="left">▇▇▇▇▇</td>
</tr>
<tr class="odd">
<td align="left">x1</td>
<td align="left">d</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">50.44</td>
<td align="right">29.03</td>
<td align="right">1.00</td>
<td align="right">25.00</td>
<td align="right">51.00</td>
<td align="right">75.00</td>
<td align="right">100.00</td>
<td align="left">▇▇▇▇▇</td>
</tr>
<tr class="even">
<td align="left">x1</td>
<td align="left">e</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">50.80</td>
<td align="right">28.77</td>
<td align="right">1.00</td>
<td align="right">26.00</td>
<td align="right">51.00</td>
<td align="right">76.00</td>
<td align="right">100.00</td>
<td align="left">▇▇▇▇▇</td>
</tr>
<tr class="odd">
<td align="left">x2</td>
<td align="left">a</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">151.41</td>
<td align="right">28.85</td>
<td align="right">101.00</td>
<td align="right">126.00</td>
<td align="right">152.00</td>
<td align="right">176.00</td>
<td align="right">200.00</td>
<td align="left">▇▇▇▇▇</td>
</tr>
<tr class="even">
<td align="left">x2</td>
<td align="left">b</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">150.12</td>
<td align="right">28.76</td>
<td align="right">101.00</td>
<td align="right">125.00</td>
<td align="right">149.00</td>
<td align="right">175.00</td>
<td align="right">200.00</td>
<td align="left">▇▇▇▇▇</td>
</tr>
<tr class="odd">
<td align="left">x2</td>
<td align="left">c</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">150.32</td>
<td align="right">28.97</td>
<td align="right">101.00</td>
<td align="right">125.00</td>
<td align="right">149.00</td>
<td align="right">175.00</td>
<td align="right">200.00</td>
<td align="left">▇▇▇▇▇</td>
</tr>
<tr class="even">
<td align="left">x2</td>
<td align="left">d</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">150.75</td>
<td align="right">28.95</td>
<td align="right">101.00</td>
<td align="right">125.00</td>
<td align="right">151.00</td>
<td align="right">175.00</td>
<td align="right">200.00</td>
<td align="left">▇▇▇▇▇</td>
</tr>
<tr class="odd">
<td align="left">x2</td>
<td align="left">e</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">150.71</td>
<td align="right">28.66</td>
<td align="right">101.00</td>
<td align="right">126.00</td>
<td align="right">151.00</td>
<td align="right">176.00</td>
<td align="right">200.00</td>
<td align="left">▇▇▇▇▇</td>
</tr>
<tr class="even">
<td align="left">x3</td>
<td align="left">a</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">250.14</td>
<td align="right">28.56</td>
<td align="right">201.00</td>
<td align="right">225.00</td>
<td align="right">249.00</td>
<td align="right">275.00</td>
<td align="right">300.00</td>
<td align="left">▇▇▇▇▇</td>
</tr>
<tr class="odd">
<td align="left">x3</td>
<td align="left">b</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">251.06</td>
<td align="right">28.97</td>
<td align="right">201.00</td>
<td align="right">225.00</td>
<td align="right">252.00</td>
<td align="right">276.00</td>
<td align="right">300.00</td>
<td align="left">▇▇▇▇▇</td>
</tr>
<tr class="even">
<td align="left">x3</td>
<td align="left">c</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">251.16</td>
<td align="right">29.12</td>
<td align="right">201.00</td>
<td align="right">226.00</td>
<td align="right">251.00</td>
<td align="right">277.00</td>
<td align="right">300.00</td>
<td align="left">▇▇▇▇▇</td>
</tr>
<tr class="odd">
<td align="left">x3</td>
<td align="left">d</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">250.07</td>
<td align="right">29.07</td>
<td align="right">201.00</td>
<td align="right">225.00</td>
<td align="right">250.00</td>
<td align="right">276.00</td>
<td align="right">300.00</td>
<td align="left">▇▇▇▇▇</td>
</tr>
<tr class="even">
<td align="left">x3</td>
<td align="left">e</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">250.01</td>
<td align="right">28.58</td>
<td align="right">201.00</td>
<td align="right">225.00</td>
<td align="right">250.00</td>
<td align="right">275.00</td>
<td align="right">300.00</td>
<td align="left">▇▇▇▇▇</td>
</tr>
</tbody>
</table>
<pre class="r"><code>bm1 &lt;- mark(
#describe_all() version
describe_all(pdata_resampled, g), 

#skimr::skim() version
skimr::skim(group_by(pdata_resampled, g)), 

  iterations = 10,
  check = FALSE)#the output isn&#39;t exactly the same so we disable the check argument</code></pre>
<pre><code>## Warning: Some expressions had a GC in every iteration; so filtering is disabled.</code></pre>
<pre class="r"><code>bm1 %&gt;% plot()</code></pre>
<p><img src="/post/2020-11-17-ASGR-3-0-exploring-data-with-elucidate/index_files/figure-html/unnamed-chunk-28-1.png" width="672" /></p>
<p>We can clearly see that <code>describe_all()</code> runs ~18% faster and uses ~26% less memory when a grouping variable with a handful of levels is specified (similar in terms of scale to most experimental designs that have &lt;= 5 treatment groups). <code>describe_all()</code> also gives you <em>more</em> information (for numeric variables: se, skew, kurtosis, proportion of values that are missing). <code>skim()</code> does produce in-line mini-histograms for numeric variables, but I find the resolution of these to be too low to really be useful and opt to instead rely on a combination of skewness, kurtosis, and looking at the data more closely with dedicated plotting functions. You also can’t export the in-line histograms as cell values to a .csv file, which obviously isn’t a problem for skewness or kurtosis.</p>
<p>However, I’ve noticed that <code>skimr::skim()</code> does seem to scale a bit better as the total number of groups used for splitting increases, so you may want to try it if you have multiple grouping variables that with many levels (e.g. postal codes/zip codes). For example, when we ask for a description of the resampled_pdata grouped by both “g” and “d” with a total of 60 level combinations, <code>skim()</code> finishes in a median time of 2.29 seconds vs. 3.45 seconds for <code>describe_all()</code>, or ~40% faster via <code>skim()</code> when describing multiple columns for each of 60 group combinations. On the other hand, an extra 1.16 seconds isn’t terrible considering that you’re still getting more information and still using 17% less memory with <code>describe_all()</code>. Something to keep in mind too is that memory efficiency can become more important than speed when you are working with larger datasets commonly encountered in government or industry (tens or hundreds of millions of rows or more).</p>
<pre class="r"><code>bm1 &lt;- mark(
  describe_all(pdata_resampled, d, g), 
  skimr::skim(group_by(pdata_resampled, d, g)),
  
  iterations = 10,
  check = FALSE) #the output isn&#39;t exactly the same so we disable the check argument</code></pre>
<pre><code>## Warning: Some expressions had a GC in every iteration; so filtering is disabled.</code></pre>
<pre class="r"><code>bm1 %&gt;% select(expression, min, median, mem_alloc)</code></pre>
<pre><code>## # A tibble: 2 x 4
##   expression                                        min   median mem_alloc
##   &lt;bch:expr&gt;                                   &lt;bch:tm&gt; &lt;bch:tm&gt; &lt;bch:byt&gt;
## 1 describe_all(pdata_resampled, d, g)             3.07s    3.14s     1.7GB
## 2 skimr::skim(group_by(pdata_resampled, d, g))    2.22s    2.34s    1.99GB</code></pre>
<pre class="r"><code>bm1 %&gt;% plot()</code></pre>
<p><img src="/post/2020-11-17-ASGR-3-0-exploring-data-with-elucidate/index_files/figure-html/unnamed-chunk-29-1.png" width="672" /></p>
<p>What about the non-grouped version that you’ll probably use most often?</p>
<pre class="r"><code>bm1 &lt;- mark(
describe_all(pdata_resampled), 

skimr::skim(pdata_resampled), 

  iterations = 10,
  check = FALSE) #the output isn&#39;t exactly the same so we disable the check argument</code></pre>
<pre><code>## Warning: Some expressions had a GC in every iteration; so filtering is disabled.</code></pre>
<pre class="r"><code>bm1 %&gt;% select(expression, min, median, mem_alloc)</code></pre>
<pre><code>## # A tibble: 2 x 4
##   expression                         min   median mem_alloc
##   &lt;bch:expr&gt;                    &lt;bch:tm&gt; &lt;bch:tm&gt; &lt;bch:byt&gt;
## 1 describe_all(pdata_resampled)    1.58s    1.59s    1.63GB
## 2 skimr::skim(pdata_resampled)     2.16s    2.18s    2.04GB</code></pre>
<pre class="r"><code>bm1 %&gt;% plot()</code></pre>
<p><img src="/post/2020-11-17-ASGR-3-0-exploring-data-with-elucidate/index_files/figure-html/unnamed-chunk-30-1.png" width="672" /></p>
<p>Here <code>describe_all()</code> comes out on top again, finishing ~40% faster and using ~25% less RAM than <code>skim()</code>.</p>
</div>
</div>
<div id="navigation" class="section level1">
<h1><span class="header-section-number">10</span> Navigation</h1>
<p>Click <a href="https://craig.rbind.io/post/2020-10-10-asgr-2-5-dates/">here</a> to go back to the previous post on dates and times. A link to the next one, on the popular tidyverse data visualization package <a href="https://ggplot2.tidyverse.org/">ggplot2</a>, will be added as soon as I have time to write it.</p>
</div>
<div id="notes" class="section level1">
<h1><span class="header-section-number">11</span> Notes</h1>
<ul>
<li><p>link to janitor package</p></li>
<li><p>I acknowledge and express their gratitude to the authors of the tidyverse packages, data.table, and the functions of other dependency packages which were used to build elucidate, since without their effort and ingenuity elucidate would mostly have remained a collection of ideas instead of functions.</p></li>
<li><p>next major component of the package to be added to facilitate clustering and dimensionality reduction, to be developed over the next year or so.</p></li>
</ul>
<p>Thank you for visiting my blog. I welcome any suggestions for future posts, comments or other feedback you might have. Feedback from beginners and science students/trainees (or with them in mind) is especially helpful in the interest of making this guide even better for them.</p>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>If you’re currently a grad student, you can learn about some of the other highly marketable skills you’re developing <a href="https://beyondprof.com/10-transferable-skills-from-your-phd-that-employers-want/">here</a>.<a href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p><a href="https://bookdown.org/yihui/rmarkdown-cookbook/">R markdown</a> is what I’m using to write these posts, you’ll learn much more about it when we get to the reporting &amp; communication part of the guide<a href="#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>The sorting occurs in descending order.<a href="#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p>If you only want the truly unique/non-duplicated rows instead use <code>copies(data, filter = "unique")</code><a href="#fnref4" class="footnote-back">↩︎</a></p></li>
<li id="fn5"><p>in case you’re wondering, yes, dplyr does have a function called <code>distinct()</code> that does the same thing as <code>copies(filter = "first")</code>, although the underlying code is different and it is less flexible<a href="#fnref5" class="footnote-back">↩︎</a></p></li>
<li id="fn6"><p>These are particularly common in psychological research, for example if you test individuals using questions that are too easy or too difficulty. Ceiling and floor effects are also why most university professors who teach tend to be concerned if the class average deviates too far from ~67%<a href="#fnref6" class="footnote-back">↩︎</a></p></li>
<li id="fn7"><p>often abbreviated as “i.i.d.”. In other words, the value of one observation is completely <em>independent</em> from the values of other observations in the sample. This is another assumption of most common (frequentist) parametric tests, like the t-test, called the “independence assumption” we’ll learn how to evaluate in a future post on hypothesis testing.<a href="#fnref7" class="footnote-back">↩︎</a></p></li>
<li id="fn8"><p>Efron, B., &amp; Tibshirani, R. J. (1994). <em>An introduction to the bootstrap</em>. CRC press.<a href="#fnref8" class="footnote-back">↩︎</a></p></li>
<li id="fn9"><p>thanks to the thoughtful authors of the <code>ggplot2</code> package, which we’ll dive into in the next post<a href="#fnref9" class="footnote-back">↩︎</a></p></li>
</ol>
</div>

    </div>

    

<div class="article-tags">
  
  <a class="badge badge-light" href="/tags/r/">R</a>
  
  <a class="badge badge-light" href="/tags/r-basics/">R basics</a>
  
</div>



    
      








  





  
  <div class="media author-card" itemscope itemtype="http://schema.org/Person">
    
      
      <img class="portrait mr-3" src="/authors/admin/avatar_hu379968d4a591158aefc150dd1b891ba0_3685589_250x250_fill_q90_lanczos_center.jpg" itemprop="image" alt="Avatar">
    

    <div class="media-body">
      <h5 class="card-title" itemprop="name"><a href="/authors/admin/">Dr. Craig P. Hutton</a></h5>
      <h6 class="card-subtitle">Data Scientist | Behavioural Neuroscientist</h6>
      
      <ul class="network-icon" aria-hidden="true">
        
          
          
          
            
          
          
          
          
          
            
          
          <li>
            <a itemprop="sameAs" href="/#contact" >
              <i class="fas fa-envelope"></i>
            </a>
          </li>
        
          
          
          
            
          
          
          
          
          
            
          
          <li>
            <a itemprop="sameAs" href="https://twitter.com/huttoncp" target="_blank" rel="noopener">
              <i class="fab fa-twitter"></i>
            </a>
          </li>
        
          
          
          
          
          
          
          
            
          
          <li>
            <a itemprop="sameAs" href="https://scholar.google.ca/citations?user=bMNjAzkAAAAJ&amp;hl=en" target="_blank" rel="noopener">
              <i class="ai ai-google-scholar"></i>
            </a>
          </li>
        
          
          
          
            
          
          
          
          
          
            
          
          <li>
            <a itemprop="sameAs" href="https://github.com/huttoncp" target="_blank" rel="noopener">
              <i class="fab fa-github"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>



      
      
      <div class="article-widget">
        <div class="hr-light"></div>
        <h3>Related</h3>
        <ul>
          
          <li><a href="/post/2020-10-10-asgr-2-5-dates/">A Scientist&#39;s Guide to R: Step 2.5 - dates &amp; times</a></li>
          
          <li><a href="/post/2020-08-29-asgr-2-4-factors/">A Scientist&#39;s Guide to R: Step 2.4 - forcats for factors</a></li>
          
          <li><a href="/post/2020-06-28-asgr-2-3-string-manipulation/">A Scientist&#39;s Guide to R: Step 2.3 - string manipulation and regex</a></li>
          
          <li><a href="/post/2020-03-29-asgr-2-2-joining-data/">A Scientist&#39;s Guide to R: Step 2.2 - Joining Data with dplyr</a></li>
          
          <li><a href="/post/2020-01-25-asgr-2-1-data-transformation-part-2/">A Scientist&#39;s Guide to R: Step 2.1 Data Transformation - part 2</a></li>
          
        </ul>
      </div>
      
    

    

    <div id="disqus_thread"></div>
<script>
(function() {
var d = document, s = d.createElement('script');
s.src = 'https://craig-rbind-io.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

  </div>
</article>

<div class="container">
  <footer class="site-footer">
  
  <p class="powered-by">
    <a href="/privacy/">Privacy Policy</a>
  </p>
  

  <p class="powered-by">
    Copyright © 2020 by Craig P. Hutton &middot; 

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" id="back_to_top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

</div>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/highlight.min.js" integrity="sha256-aYTdUrn6Ow1DDgh5JTc3aDGnnju48y/1c8s1dgkYPQ8=" crossorigin="anonymous"></script>
        
      

      
      
    

    
    

    
    
    
    <script id="dsq-count-scr" src="//craig-rbind-io.disqus.com/count.js" async></script>
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script>
      const search_index_filename = "/index.json";
      const i18n = {
        'placeholder': "Search...",
        'results': "results found",
        'no_results': "No results found"
      };
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.ee8463f2a394889d45e169a983fe913d.js"></script>

  </body>
</html>


